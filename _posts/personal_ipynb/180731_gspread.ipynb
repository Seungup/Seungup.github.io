{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SpreadsheetNotFound",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gspread/client.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_spreadsheet_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gspread/utils.py\u001b[0m in \u001b[0;36mfinditem\u001b[0;34m(func, seq)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSpreadsheetNotFound\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2bc948b968fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServiceAccountCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_keyfile_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/frhyme/Downloads/My Project-6f3701259a8e.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m## authorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgspread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!individual_meet_report\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;31m## sheet file 이름을 넘겨주고 읽습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mwks0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_worksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gspread/client.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSpreadsheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mSpreadsheetNotFound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_by_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSpreadsheetNotFound\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 필요한 라이브러리들은 모두 여기서 한번에 import \n",
    "- font 또한 여기서 한번에 정리한다. \n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from collections import Counter, namedtuple\n",
    "\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import gspread\n",
    "\n",
    "## fontproperties 설정\n",
    "BMDOHYEON = fm.FontProperties(fname='/Users/frhyme/Library/Fonts/BMDOHYEON_otf.otf')\n",
    "BMJUA = fm.FontProperties(fname='/Users/frhyme/Library/Fonts/BMJUA_otf.otf')\n",
    "BMHANNA = fm.FontProperties(fname='/Users/frhyme/Library/Fonts/BMHANNA_11yrs_otf.otf')\n",
    "SDMiSaeng = fm.FontProperties(fname='/Users/frhyme/Library/Fonts/SDMiSaeng.ttf')\n",
    "nanum = fm.FontProperties(fname='/Library/Fonts/NanumSquareOTFB.otf')\n",
    "TimesNewRoman = fm.FontProperties(fname='/Library/Fonts/Times New Roman.ttf')\n",
    "\n",
    "## 구글 시트로부터, 파일을 읽고 리리스트에 정리해줌\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('/Users/frhyme/Downloads/My Project-6f3701259a8e.json', scope)\n",
    "## authorize\n",
    "gc = gspread.authorize(credentials).open(\"!individual_meet_report\")\n",
    "## sheet file 이름을 넘겨주고 읽습니다. \n",
    "wks0 = gc.get_worksheet(0)\n",
    "wks1 = gc.get_worksheet(1)\n",
    "all_rows = wks0.get_all_values()[1:] + wks1.get_all_values()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-43f2b92b11eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mraw_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_rows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpeople\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## 비어있는 셀 삭제\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpeople\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeople\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## 공백제거\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_rows' is not defined"
     ]
    }
   ],
   "source": [
    "raw_df = []\n",
    "for row in all_rows:\n",
    "    date, category = row[0], row[3].strip() \n",
    "    people = filter(lambda x: True if x.strip()!=\"\" else False, row[4:]) ## 비어있는 셀 삭제 \n",
    "    people = map(lambda x: x.strip(), people) ## 공백제거\n",
    "    people = sorted(list(set(people))) ## 사람 이름 순으로 정렬해야 양방향성 서로다른 edge가 생기지 않음\n",
    "    people.remove('이승훈')## 내가 들어있는 데이터는 무의미함. \n",
    "    raw_df.append((date, category, people))## 이렇게 정리하여 raw_df에 넣고 \n",
    "\n",
    "## 데이터 프레임으로 변경하고, 정렬, index 리셋등 \n",
    "## (date, category, people_lst)로 정리된 dataframe\n",
    "raw_df = pd.DataFrame(raw_df, columns=['date', 'category', 'people'])\n",
    "raw_df['date'] = pd.to_datetime(raw_df['date'])\n",
    "raw_df = raw_df.sort_values('date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 인맥별만남누적비율그래프_plot():\n",
    "## (사람, 만남빈도) 에 따라서 만든 df\n",
    "    p_count_df = pd.DataFrame(Counter(itertools.chain.from_iterable(raw_df.people)).most_common(), columns=['people', 'count'])\n",
    "    p_count_df['cum_percent'] = p_count_df['count'].cumsum()/(p_count_df['count'].sum())*100\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ## zorder는 일종의 layer의 우선순위 라고 생각하면 됨. 무엇이 가장 아래에 있고, 위에 있을 것인가를 결정해주는 것 \n",
    "    plt.plot(p_count_df['cum_percent'], '--', color='red', alpha=0.5, linewidth=3, zorder=-1)\n",
    "\n",
    "    ## 10, 50, 100명의 인맥이 전체 만남의 어느 정도의 누적 비율을 차지하는지 정리 \n",
    "    scatter_lst = np.array([(i-1, p_count_df['cum_percent'].iloc()[i-1]) for i in [10, 50, 100]])\n",
    "    plt.scatter(scatter_lst[:, 0], scatter_lst[:, 1], marker='o', s=500, color='red')\n",
    "    xytext_lst = [(250, 25), (300, 50), (350, 75)]\n",
    "    for i, xy in enumerate(scatter_lst):\n",
    "        x, y = xy\n",
    "        plt.annotate('인맥 상위 {:d}명 => {:.1f}%'.format(int(x+1), y), \n",
    "                     xy=xy, xytext=xytext_lst[i], fontsize=20, fontproperties= BMJUA, \n",
    "                     arrowprops=dict(facecolor='black', shrink=0.05, width=3, headwidth=10, edgecolor='black')\n",
    "                )\n",
    "    plt.xlabel('인맥', fontproperties= BMJUA)\n",
    "    plt.ylabel(\"인맥별 만남 누적 %\", fontproperties= BMJUA)\n",
    "    plt.xticks(np.arange(0, 650, 150), \n",
    "               ['P_{:0<2d}'.format(p) for p in np.arange(0, 650, 150)], fontproperties=BMJUA, fontsize=12, )\n",
    "    plt.yticks(np.arange(0, 105, 25), \n",
    "               ['{}%'.format(x) for x in np.arange(0, 105, 25)], fontproperties=BMJUA, fontsize=12, )\n",
    "    plt.title(\"인맥 별 만남 누적 비율\", fontproperties=BMJUA)\n",
    "    plt.savefig('../../assets/images/markdown_img/180801_people_cumu_sum.png', dpi=200)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 단 1번만 만난 사람 수 \n",
    "## 전체 643명 중에서 234명을 단 한번만 만났고, 이는 약 36%\n",
    "def 만남횟수별인맥_bar():\n",
    "    p_count_df = pd.DataFrame(Counter(itertools.chain.from_iterable(raw_df.people)).most_common(), columns=['people', 'count'])\n",
    "    p_count_df['cum_percent'] = p_count_df['count'].cumsum()/(p_count_df['count'].sum())*100\n",
    "\n",
    "    xy = [(\"{}\".format(i), np.sum(p_count_df['count']<=i)/len(p_count_df)*100) for i in [1, 2, 5, 10, ]]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar([x[0] for x in xy], [x[1] for x in xy], \n",
    "            width=0.7, color='purple', alpha=0.6\n",
    "            #edgecolor='black', #linewidth=5, \n",
    "           )\n",
    "    ## bar 별로 글자 넣어주기 \n",
    "    for i, _xy in enumerate(xy):\n",
    "        x, y = _xy\n",
    "        plt.text(i-0.14, y+3, s='{:.1f}%'.format(y), \n",
    "                 fontproperties=BMJUA, fontsize=20, color='crimson'\n",
    "                )\n",
    "    ## yticks 설정\n",
    "    plt.ylim(0, 100)\n",
    "    loc, label = plt.yticks()\n",
    "    plt.yticks(loc, [\"{:2.0f}%\".format(y) for y in np.linspace(0, 100, 6)], fontproperties=BMJUA, fontsize=12)\n",
    "    ## xticks 설정 \n",
    "    loc, label = plt.xticks()\n",
    "    plt.xticks(loc, ['{}번 이하'.format(x[0]) for x in xy], fontproperties=BMJUA, fontsize=15)\n",
    "    plt.xlabel(\"전체 인맥 중 x 번 이하 만난 인맥 비율\", fontproperties=BMJUA)\n",
    "    plt.savefig(\"../../assets/images/markdown_img/180802_n_above_people_bar_char.png\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read context sheet\n",
    "context_sheet = gc.get_worksheet(-1)\n",
    "people_tuple = namedtuple(\"people\", 'name others')\n",
    "people_context_dt = {}## key: 이름, value: 속한집단('남', '연구실' 등)\n",
    "## context를 읽어서 딕셔너리 리스트로 정리합니다. \n",
    "for p in context_sheet.get_all_values()[1:]:\n",
    "    p = filter(lambda x: True if x!='' else False, p)\n",
    "    p = list(map(lambda x: x.strip(), p))\n",
    "    people_context_dt[p[0]] = p[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 전체인맥중남녀비율_pie():\n",
    "    ## 인맥 중 남녀 비율 \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    temp = Counter(['남' if '남' in v else '여' for v in people_context_lst.values()]).most_common()\n",
    "    labels, xs = [x[0] for x in temp], [x[1] for x in temp]\n",
    "    patches, texts, autotexts = plt.pie(labels = labels, x=xs, autopct='%1.1f%%', startangle=0, counterclock=False,explode=(0, 0.1)\n",
    "                                       )\n",
    "    for t in texts:\n",
    "        t.set_color(\"black\"), t.set_fontproperties(BMDOHYEON), t.set_fontsize(20)\n",
    "    ## pie 위의 텍스트를 다른 색으로 변경해주기 \n",
    "    for t in autotexts:\n",
    "        t.set_color(\"white\"), t.set_fontproperties(BMDOHYEON), t.set_fontsize(20)\n",
    "    ## 리턴받은 patche 중에서 남자인 부분은 연하게 하고 여자인 부분의 색은 강하게 하여 변화시킴 \n",
    "    patches[0].set_alpha(0.5), \n",
    "\n",
    "    patches[1].set_color(\"red\"), patches[1].set_edgecolor('black')\n",
    "    patches[1].set_linestyle('--'), patches[1].set_linewidth(3)\n",
    "\n",
    "    ######\n",
    "    plt.title(\"인맥 중 남녀 비율\", fontproperties=BMJUA, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"../../assets/images/markdown_img/180802_people_gender_ratio.png\", dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "def 인맥중학교사람비율_pi():\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    temp = Counter(['yes' if '포스텍' in v else 'no' for v in people_context_lst.values()]).most_common()\n",
    "    labels, xs = [x[0] for x in temp], [x[1] for x in temp]\n",
    "    patches, texts, autotexts = plt.pie(labels = labels, \n",
    "                                        x=xs, autopct='%1.1f%%',\n",
    "                                        startangle=0,counterclock=False,explode=(0, 0.1)\n",
    "                                       )\n",
    "    for t in texts:\n",
    "        t.set_color(\"black\"), t.set_fontproperties(BMDOHYEON), t.set_fontsize(20)\n",
    "    ## pie 위의 텍스트를 다른 색으로 변경해주기 \n",
    "    for t in autotexts:\n",
    "        t.set_color(\"white\"), t.set_fontproperties(BMDOHYEON), t.set_fontsize(20)\n",
    "    ## 포스텍만 강조 \n",
    "    patches[0].set_alpha(0.8), patches[1].set_alpha(0.2)\n",
    "    patches[0].set_color(\"red\"), patches[1].set_color(\"blue\"), \n",
    "    patches[0].set_edgecolor('black'), patches[0].set_linestyle('--'), patches[0].set_linewidth(3)\n",
    "\n",
    "\n",
    "    ######\n",
    "    plt.title(\"인맥 중 학교사람 비율\", fontproperties=BMJUA, fontsize=20)\n",
    "    #plt.savefig(\"../../assets/images/markdown_img/180802_people_in_postech.png\", dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "def 전체만남중남녀비율_pie():\n",
    "    ## 만남 중 남녀 비율 \n",
    "    ## 일단 raw_df에서 people_context에 있는 놈들만 걸러내고\n",
    "    temp_df = raw_df['people'].apply(lambda lst: list(filter(lambda x: True if x in people_context_lst.keys() else False, lst)))\n",
    "    ## 다시 df를 만든 다음 \n",
    "    temp_df = list(itertools.chain.from_iterable(temp_df))\n",
    "\n",
    "    ## 전체 만남 중 여자 비율 \n",
    "    result = Counter(map(lambda x: '여' if '여' in people_context_lst[x] else '남', temp_df))\n",
    "\n",
    "    labels, xs = result.keys(), result.values()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    patches, texts, autotexts = plt.pie(labels = labels, x=xs, autopct='%1.1f%%',startangle=0,\n",
    "                                        counterclock=False,explode=(0, 0.1) )\n",
    "    for t in texts:\n",
    "        t.set_color(\"black\"), t.set_fontproperties(BMDOHYEON), t.set_fontsize(20)\n",
    "    ## pie 위의 텍스트를 다른 색으로 변경해주기 \n",
    "    for t in autotexts:\n",
    "        t.set_color(\"white\"), t.set_fontproperties(BMDOHYEON), t.set_fontsize(20)\n",
    "    ## 여자 부분만 강조 \n",
    "    patches[0].set_alpha(0.5)\n",
    "    patches[1].set_color(\"red\"), patches[1].set_edgecolor('black')\n",
    "    patches[1].set_linestyle('--'), patches[1].set_linewidth(3)\n",
    "\n",
    "    ######\n",
    "    plt.title(\"만남 중 남녀 비율\", fontproperties=BMJUA, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"../../assets/images/markdown_img/180802_meet_gender_ratio.png\", dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "def 전체만남중_여자친구_어머니_제외시_남녀비율_pie():\n",
    "    temp_df = raw_df['people'].apply(lambda lst: list(filter(lambda x: True if x in people_context_lst.keys() else False, lst)))\n",
    "    temp_df = list(itertools.chain.from_iterable(temp_df))\n",
    "\n",
    "    ## 전체 만남 중 여자 비율 여자친구/어머니 제외 \n",
    "    result = Counter(map(lambda x: '여' if '여' in people_context_lst[x] and '어머니' not in people_context_lst[x] and '여자친구' not in people_context_lst[x]\n",
    "                         else '남', temp_df))\n",
    "\n",
    "    labels, xs = result.keys(), result.values()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    patches, texts, autotexts = plt.pie(labels = labels, x=xs, autopct='%1.1f%%',\n",
    "                                        startangle=0, pctdistance=0.75, labeldistance=1.02, \n",
    "                                        counterclock=False,explode=(0, 0.2))\n",
    "    for t in texts:\n",
    "        t.set_color(\"black\"), t.set_fontproperties(BMDOHYEON), t.set_fontsize(20)\n",
    "    ## pie 위의 텍스트를 다른 색으로 변경해주기 \n",
    "    for t in autotexts:\n",
    "        t.set_color(\"white\"), t.set_fontproperties(BMDOHYEON), t.set_fontsize(18)\n",
    "    ## 여자 부분만 강조 \n",
    "    patches[0].set_alpha(0.5)\n",
    "    patches[1].set_color(\"red\"), patches[1].set_edgecolor('black')\n",
    "    patches[1].set_linestyle('--'), patches[1].set_linewidth(3)\n",
    "\n",
    "    ######\n",
    "    plt.title(\"만남 중 남녀 비율(여자친구/어머니 제외)\", fontproperties=BMJUA, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"../../assets/images/markdown_img/180802_meet_gender_ratio_without.png\", dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "def 만남중_가족여자친구비율비교_pi():\n",
    "    temp_df = raw_df['people'].iloc()[:4812].apply(lambda lst: list(filter(lambda x: True if x in ['어머니', '이정호', '임소희'] else False, lst)))\n",
    "    temp_df = list(itertools.chain.from_iterable(temp_df))\n",
    "    temp_df = map(lambda x: '가족' if x in ['이정호', '어머니'] else '여자친구', temp_df)\n",
    "    temp = Counter(temp_df).most_common()\n",
    "\n",
    "    labels, xs = [x[0] for x in temp], [x[1] for x in temp]\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    patches, texts, autotexts = plt.pie(labels = labels, \n",
    "                                        x=xs, autopct='%1.1f%%', startangle=270,\n",
    "                                        counterclock=False,explode=(0, 0.1)\n",
    "                                       )\n",
    "    for t in texts:\n",
    "        t.set_color(\"black\"), t.set_fontproperties(BMDOHYEON), t.set_fontsize(20)\n",
    "    ## pie 위의 텍스트를 다른 색으로 변경해주기 \n",
    "    for t in autotexts:\n",
    "        t.set_color(\"white\"), t.set_fontproperties(BMDOHYEON), t.set_fontsize(20)\n",
    "    ## 포스텍만 강조 \n",
    "    patches[0].set_alpha(0.8), patches[1].set_alpha(0.2)\n",
    "    patches[0].set_color(\"red\"), patches[1].set_color(\"blue\"), \n",
    "    patches[0].set_edgecolor('black'), patches[0].set_linestyle('--'), patches[0].set_linewidth(3)\n",
    "\n",
    "    ######\n",
    "    plt.title(\"만남 중 가족/여자친구 비율 비교\", fontproperties=BMJUA, fontsize=20)\n",
    "    #plt.savefig(\"../../assets/images/markdown_img/180802_family_girlfriend_comp.png\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그래프 생성 \n",
    "G = nx.Graph()\n",
    "## add node \n",
    "G.add_nodes_from([(name, {'weight':count}) \n",
    "                  for name, count in Counter(itertools.chain.from_iterable(raw_df.people)).most_common()])\n",
    "## add edge \n",
    "edges = []\n",
    "for row in raw_df.people:\n",
    "    ## 이미 위에서 정렬을 했지만, 그냥 한 번 더 해줌 깔깔 \n",
    "    edges += [tuple(sorted([row[i], row[j]])) for i in range(0, len(row)-1) for j in range(i+1, len(row))]\n",
    "G.add_edges_from([(edge[0], edge[1],{'weight':count}) for edge, count in Counter(edges).most_common()])\n",
    "#G.add_weighted_edges_from(Counter(edges).most_common())\n",
    "\n",
    "## 딱 한 번 만난 인맥은 지우자 \n",
    "def remove_below_n_nodes(inputG, below_n):\n",
    "    remove_nodes = filter(lambda n: True if n[1]['weight']<below_n else False, inputG.nodes(data=True))\n",
    "    remove_nodes = map(lambda x: x[0], remove_nodes)\n",
    "    inputG.remove_nodes_from(list(remove_nodes))\n",
    "## 잘못 들어간 node를 지워주는 것이 필요한데, 이 부분은 작업하면서 일관적으로 해주는 것이 중요함. \n",
    "## 가장 긴 shortest_path를 찾은 다음, 거기에 포함된 양 쪽에 이상한 node가 들어있지 않은지 파악하는 것이 필요. \n",
    "G.remove_nodes_from(['김태웅', '김용중', '여자1', '여자2', '여자3', '여자4', '남자1', \n",
    "                     '박병후', '김근수', '여자2', '김동혁', '배미라', '이유진', '정원욱', '이지수'])\n",
    "## 이상한 몇 가지 node를 지우자 \n",
    "## 누군지 기억이 잘 나지 않는 node는 지워야 합니다. \n",
    "# G.remove_nodes_from(remove_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 케빈 베이컨 문제 전체 대상 \n",
    "## connected component를 보면, 가장 큰 connected component가 575개. \n",
    "## \n",
    "subG_lst = [subG for subG in nx.connected_component_subgraphs(G)]\n",
    "for i, subG in enumerate(subG_lst):\n",
    "    print(\"subGraph {}, size: {}\".format(i, len(subG.nodes())))\n",
    "## 이제 그렇다면, 가장 큰 사이즈의 subG 의 \n",
    "## shortest_path pair중에서 가장 긴 것의 길이가 7을 넘지 않으면 됨. \n",
    "max_size_subG = max(subG_lst, key=lambda x: len(x.nodes()))\n",
    "#list(nx.shortest_path_length(max_size_subG))\n",
    "len(max_size_subG.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.diameter(max_size_subG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_short_lens = [len(nx.shortest_path(max_size_subG, n1, n2)) for n1, n2 in combinations(max_size_subG.nodes(), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 평균적으로 \n",
    "sum(all_short_lens)/len(all_short_lens)\n",
    "print(\"mean: {} std: {}\".format(np.mean(all_short_lens), np.std(all_short_lens)))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(all_short_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "plt.figure(figsize=(12, 6))\n",
    "pos = nx.random_layout(max_size_subG)\n",
    "nx.draw_networkx_edges(max_size_subG, pos, alpha=0.5)\n",
    "nx.draw_networkx_nodes(max_size_subG, pos, node_size=30)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../assets/images/markdown_img/180802_network_graph.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_paths = []\n",
    "for n1, n2 in combinations(max_size_subG.nodes(), 2):\n",
    "    new_path = nx.shortest_path(max_size_subG, n1, n2)\n",
    "    if len(new_path)==8:\n",
    "        all_possible_paths.append(new_path)\n",
    "## all_possible_paths\n",
    "## ['심찬양', '김미현', '강지우', '백상현', '빈영욱', '임소희', '어머니', '정수익'] \n",
    "## 이 path로 케빈베이컨이 된다 는 것을 보여주면 되겠네. \n",
    "for p in all_possible_paths:\n",
    "    if '심찬양' in p:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## centrality df \n",
    "def centrality_df(inputG):\n",
    "    r_df = pd.DataFrame(list(nx.degree_centrality(max_size_subG).items()), columns=['name', 'deg_cent'])\n",
    "    r_df = r_df.merge( pd.DataFrame(list(nx.closeness_centrality(max_size_subG).items()), columns=['name', 'clo_cent']), \n",
    "                 how='inner', on='name')\n",
    "    r_df = r_df.merge( pd.DataFrame(list(nx.betweenness_centrality(max_size_subG).items()), columns=['name', 'bet_cent']), \n",
    "                 how='inner', on='name')\n",
    "    return r_df\n",
    "cent_df = centrality_df(max_size_subG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## centrality df \n",
    "def centrality_df(inputG):\n",
    "    r_df = pd.DataFrame(list(nx.degree_centrality(max_size_subG).items()), columns=['name', 'deg_cent'])\n",
    "    r_df = r_df.merge( pd.DataFrame(list(nx.closeness_centrality(max_size_subG).items()), columns=['name', 'clo_cent']), \n",
    "                 how='inner', on='name')\n",
    "    r_df = r_df.merge( pd.DataFrame(list(nx.betweenness_centrality(max_size_subG).items()), columns=['name', 'bet_cent']), \n",
    "                 how='inner', on='name')\n",
    "    return r_df\n",
    "cent_df = centrality_df(max_size_subG)\n",
    "\n",
    "## remove node by degree centrality\n",
    "temp_dict = {'deg':[], 'clo':[], 'bet':[]}\n",
    "tempG = max_size_subG.copy()\n",
    "for n in cent_df.sort_values('deg_cent', ascending=False)['name'][:75]:\n",
    "    tempG.remove_node(n)\n",
    "    subgraph_len_lst = [ len(g.nodes()) for g in nx.connected_component_subgraphs(tempG)]\n",
    "    temp_dict['deg'].append(max(subgraph_len_lst))\n",
    "    #print(\"-\"*20)\n",
    "    \n",
    "## remove node by degree centrality\n",
    "tempG = max_size_subG.copy()\n",
    "for n in cent_df.sort_values('clo_cent', ascending=False)['name'][:75]:\n",
    "    tempG.remove_node(n)\n",
    "    subgraph_len_lst = [ len(g.nodes()) for g in nx.connected_component_subgraphs(tempG)]\n",
    "    temp_dict['clo'].append(max(subgraph_len_lst))\n",
    "\n",
    "    ## remove node by degree centrality\n",
    "## bet가 높은 node를 자르면, 가장 큰 subgraph의 크기가 뚝뚝 떨어지기 시작함. \n",
    "## 다르게 말하면, 나의 전체 인맥 네트워크를 잘 관리하기 위해서는, \n",
    "## 자주 보는 친구보다 나와 볼 일이 없는 친구를 일부러라도 종종 보는 것이 필요하다?? \n",
    "tempG = max_size_subG.copy()\n",
    "for n in cent_df.sort_values('bet_cent', ascending=False)['name'][:75]:\n",
    "    tempG.remove_node(n)\n",
    "    subgraph_len_lst = [ len(g.nodes()) for g in nx.connected_component_subgraphs(tempG)]\n",
    "    temp_dict['bet'].append(max(subgraph_len_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(14, 5))\n",
    "plt.plot(pd.DataFrame(temp_dict), linestyle='--', linewidth=2)\n",
    "#plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## weighted degree centrality \n",
    "def return_weighted_degree_centrality(input_g, normalized=False):\n",
    "    w_d_centrality = {n:0.0 for n in input_g.nodes()}\n",
    "    for u, v, d in input_g.edges(data=True):\n",
    "        w_d_centrality[u]+=d['weight']\n",
    "        w_d_centrality[v]+=d['weight']\n",
    "    if normalized==True:\n",
    "        weighted_sum = sum(w_d_centrality.values())\n",
    "        return {k:v/weighted_sum for k, v in w_d_centrality.items()}\n",
    "    else:\n",
    "        return w_d_centrality\n",
    "## w_deg_df = pd.DataFrame(list(return_weighted_degree_centrality(max_size_subG).items()), columns=['name', 'w_deg_cent'])\n",
    "w_deg_df = pd.DataFrame(list(nx.degree_centrality(max_size_subG).items()), columns=['name', 'w_deg_cent'])\n",
    "## weighted degree의 경우 빈도와 큰 차이가 없음 \n",
    "w_deg_df.sort_values(\"w_deg_cent\", ascending=False)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_G = max_size_subG.copy()\n",
    "for i in range(0, 10):\n",
    "    temp_G.remove_node(w_deg_df['name'].iloc()[i])\n",
    "    print( [ len(g.nodes()) for g in nx.connected_component_subgraphs(temp_G)] )\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## closeness centrality \n",
    "def return_closeness_centrality(input_g):\n",
    "    new_g_with_distance = input_g.copy()\n",
    "    for u,v,d in new_g_with_distance.edges(data=True):\n",
    "        if 'distance' not in d:\n",
    "            d['distance'] = 1.0/d['weight']\n",
    "    return nx.closeness_centrality(new_g_with_distance, distance='distance')\n",
    "close_df = pd.DataFrame(list(return_closeness_centrality(max_size_subG).items()), columns=['name', 'clo_cent'])\n",
    "## without weight \n",
    "#close_df = pd.DataFrame(list(nx.closeness_centrality(max_size_subG).items()), columns=['name', 'clo_cent'])\n",
    "close_df.sort_values('clo_cent', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(nx.closeness_centrality(max_size_subG).items()), \n",
    "             columns=['name', 'clo_cent']).sort_values(\"clo_cent\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_shortest_length(inputG):\n",
    "    r_lst = []\n",
    "    for x, y in nx.all_pairs_shortest_path_length(inputG):\n",
    "        r_lst+=list(y.values())\n",
    "    return sum(r_lst)/len(r_lst)\n",
    "\n",
    "temp_G = max_size_subG.copy()\n",
    "print(len(list(nx.connected_components(temp_G))))\n",
    "\n",
    "print( average_shortest_length(max_size_subG) )\n",
    "print(\"-\"*20)\n",
    "temp_G.remove_node('백상현')\n",
    "print(len(list(nx.connected_components(temp_G))))\n",
    "print( average_shortest_length(temp_G) )\n",
    "print(\"-\"*20)\n",
    "temp_G.remove_node('이주석')\n",
    "print(len(list(nx.connected_components(temp_G))))\n",
    "print( average_shortest_length(temp_G) )\n",
    "print(\"-\"*20)\n",
    "temp_G.remove_node('이진연')\n",
    "print(len(list(nx.connected_components(temp_G))))\n",
    "print( average_shortest_length(temp_G) )\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_df = pd.DataFrame(list(nx.betweenness_centrality(max_size_subG).items()), columns=['name', 'bet_cent'])\n",
    "bet_df = bet_df.sort_values('bet_cent', ascending=False)\n",
    "bet_df['name']\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그러니까 만약 백상현 node를 지우면, 전체 shortest path가 늘어나야 됨. \n",
    "## betweeness centrality가 높은 것을 잘라나가다 보면, 제일 큰 네트워크의 사이즈가 갑자기 툭 떨어지는 순간이 발생함\n",
    "## \n",
    "def max_shortest_path_len(inputG):\n",
    "    r_lst = []\n",
    "    for x, y in nx.all_pairs_shortest_path_length(inputG):\n",
    "        r_lst.append(max(y.values()))\n",
    "    return max(r_lst)\n",
    "## betweeness 높은 노드를 두 개만 잘라도, 전체 longest_shortest_path가 늘어나다가 모든 노드가 연결되지 못하고 노드끼리 연결되지 못하는 상황이 발생함\n",
    "temp_G = max_size_subG.copy()\n",
    "for i, g in enumerate(nx.connected_component_subgraphs(temp_G)):\n",
    "    print(i, len(g.nodes()))\n",
    "print(\"-\"*20)\n",
    "for i in range(0, 50):\n",
    "    temp_G.remove_node(bet_df['name'].iloc()[i])\n",
    "    print( [ len(g.nodes()) for g in nx.connected_component_subgraphs(temp_G)] )\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 시간대별 만나는 사람의 변화 \n",
    "## 아침, 점심, 저녁, 야식+술_소주 + 술_맥주 \n",
    "def 시간대별만나는사람변화():\n",
    "    r_dict={}\n",
    "    for category in ['아침', '점심', '저녁']:\n",
    "        temp_v = Counter(itertools.chain.from_iterable(raw_df[raw_df['category'] == category]['people'])).most_common(12)\n",
    "        r_dict[category] = temp_v\n",
    "    r_dict['술+야식'] = Counter(itertools.chain.from_iterable(\n",
    "        raw_df[list(map(lambda x: True if '술' in x or '야식' in x else False, raw_df['category']))]['people']\n",
    "    )).most_common(12)\n",
    "    return r_dict\n",
    "시간대별만나는사람변화()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 월별 만나는 인맥 수, 사람 수의 변화 \n",
    "def 월별만나는인맥수변화():\n",
    "    ym_lst = []\n",
    "    meet_lst = []\n",
    "    people_lst = []\n",
    "    for g_name, group in raw_df.groupby(lambda idx: \"{}_{:1d}\".format(raw_df['date'].loc()[idx].year, raw_df['date'].loc()[idx].month//2)):\n",
    "        all_meet = itertools.chain.from_iterable(group['people'])\n",
    "        all_meet = list(all_meet)\n",
    "        all_people = list(set(all_meet))\n",
    "        ym_lst.append(g_name)\n",
    "        meet_lst.append(len(all_meet))\n",
    "        people_lst.append(len(all_people))\n",
    "    ym_df = pd.DataFrame({'meet':meet_lst[1:], 'people':people_lst[1:]}, index=ym_lst[1:])\n",
    "    ym_df['m_div_p'] = ym_df['meet']/ym_df['people']\n",
    "\n",
    "    ## 월별 인맥의 수는 점차 감소하고 있음. \n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(ym_df['people'], marker='o', markersize=8, \n",
    "             linestyle='-', linewidth=2, color='coral')\n",
    "\n",
    "    plt.title(\"인맥 수의 변화(2개월 단위)\", fontproperties=BMJUA, fontsize=20)\n",
    "    plt.xticks(fontproperties=BMHANNA, rotation=45, fontsize=12), plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('../../assets/images/markdown_img/180802_month_2_people_change.png', dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "def 월별만나는사람수변화():\n",
    "    ym_lst = []\n",
    "    meet_lst = []\n",
    "    people_lst = []\n",
    "    for g_name, group in raw_df.groupby(lambda idx: \"{}_{:1d}\".format(raw_df['date'].loc()[idx].year, raw_df['date'].loc()[idx].month//2)):\n",
    "        all_meet = itertools.chain.from_iterable(group['people'])\n",
    "        all_meet = list(all_meet)\n",
    "        all_people = list(set(all_meet))\n",
    "        ym_lst.append(g_name)\n",
    "        meet_lst.append(len(all_meet))\n",
    "        people_lst.append(len(all_people))\n",
    "    ym_df = pd.DataFrame({'meet':meet_lst[1:], 'people':people_lst[1:]}, index=ym_lst[1:])\n",
    "    ym_df['m_div_p'] = ym_df['meet']/ym_df['people']\n",
    "\n",
    "    meet_div_people = np.array(meet_lst) / np.array(people_lst)\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(ym_df['m_div_p'], marker='o', markersize=8, \n",
    "             linestyle='-', linewidth=2, color='hotpink')\n",
    "    plt.xticks(fontproperties=BMHANNA, rotation=45, fontsize=12), plt.yticks([])\n",
    "    plt.title(\"인맥별 평균 만남수 변화(2개월 단위)\", fontproperties=BMJUA, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('../../assets/images/markdown_img/180802_month_2_avg_meet_people_change.png', dpi=200)\n",
    "    plt.show()\n",
    "월별만나는인맥수변화()\n",
    "월별만나는사람수변화()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 월별 만나는 인맥 수, 사람 수의 변화 \n",
    "def 월별만나는사람수변화():\n",
    "    ym_lst = []\n",
    "    meet_lst = []\n",
    "    people_lst = []\n",
    "    for g_name, group in raw_df.groupby(lambda idx: \"{}_{:1d}\".format(raw_df['date'].loc()[idx].year, raw_df['date'].loc()[idx].month//2)):\n",
    "        all_meet = itertools.chain.from_iterable(group['people'])\n",
    "        all_meet = list(all_meet)\n",
    "        all_people = list(set(all_meet))\n",
    "        ym_lst.append(g_name)\n",
    "        meet_lst.append(len(all_meet))\n",
    "        people_lst.append(len(all_people))\n",
    "    ym_df = pd.DataFrame({'meet':meet_lst[1:], 'people':people_lst[1:]}, index=ym_lst[1:])\n",
    "    ym_df['m_div_p'] = ym_df['meet']/ym_df['people']\n",
    "\n",
    "    meet_div_people = np.array(meet_lst) / np.array(people_lst)\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(ym_df['m_div_p'], marker='o', markersize=8, \n",
    "             linestyle='-', linewidth=2, color='hotpink')\n",
    "    plt.xticks(fontproperties=BMHANNA, rotation=45, fontsize=12), plt.yticks([])\n",
    "    plt.title(\"인맥별 평균 만남수 변화(2개월 단위)\", fontproperties=BMJUA, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('../../assets/images/markdown_img/180802_month_2_avg_meet_people_change.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 월별 인맥 과 만남 수의 변화 \n",
    "G_lst = []\n",
    "G_name_lst = []\n",
    "for g_name, group in raw_df.groupby(lambda idx: \"{}_{:0>2d}\".format(raw_df['date'].loc()[idx].year, raw_df['date'].loc()[idx].month)):\n",
    "    g = nx.Graph()\n",
    "    ## add node\n",
    "    g.add_nodes_from([(name, {'weight':count}) \n",
    "                      for name, count in Counter(itertools.chain.from_iterable(group.people)).most_common()])\n",
    "    ## add edge \n",
    "    edges = []\n",
    "    for row in group.people:\n",
    "        edges += [tuple(sorted([row[i], row[j]])) for i in range(0, len(row)-1) for j in range(i+1, len(row))]\n",
    "    g.add_edges_from([(edge[0], edge[1],{'weight':count}) for edge, count in Counter(edges).most_common()])\n",
    "    G_name_lst.append(g_name)\n",
    "    G_lst.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 히스토그램 위드 밸류 \n",
    "r = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plt.text\n",
    "[(x[i]+x[i+1])/2 for i in range(0, len(xs)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make donut chart \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 고치지 말것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 테스트 그래프 생성\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from([chr(c) for c in range(ord('A'), ord('A')+15)])\n",
    "# add edge\n",
    "G.add_edges_from([('A', n) for n in list(G.node())[:10]])\n",
    "G.add_edges_from([('G', n) for n in list(G.node())[11:]])\n",
    "G.add_edges_from([('B', 'J'), ('C', 'J'), ('C', 'H'), ('H', 'E'), ('E', 'D'), ('D', 'I'), \n",
    "                  ('I', 'F'), ('B', 'K'), ('K', 'F')])\n",
    "G.add_edges_from([('O', 'N'), ('N', 'L'), ('M', 'L'), ('O', 'K'), ('K', 'M')])\n",
    "G.add_edges_from([('A', 'K'), ('G', 'K')])\n",
    "G.remove_edge('A', 'G'), \n",
    "pos = nx.spring_layout(G)\n",
    "#G.remove_node('K')\n",
    "#G.remove_nodes_from(['A', 'G'])\n",
    "####\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_shape='o', node_size=2000, \n",
    "                       node_color='pink'\n",
    "                       #node_color=['Red' if n is 'K' else 'pink'  for n in G.nodes()]\n",
    "                      )\n",
    "nx.draw_networkx_edges(G, pos, width=2)\n",
    "## font family에는 font_name이 들어가야 함. 블로그에 정리해둠\n",
    "nx.draw_networkx_labels(\n",
    "        G, pos, font_family='BM JUA_OTF', font_color='black', font_size=20, #font_weight='bold'\n",
    "    )\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('../../assets/images/markdown_img/180807_centrality_deg_bet_net.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_shape='o', node_size=2000, \n",
    "                       node_color=['Red' if n is 'A' else 'pink'  for n in G.nodes()]\n",
    "                      )\n",
    "nx.draw_networkx_edges(G, pos, width=2)\n",
    "## font family에는 font_name이 들어가야 함. 블로그에 정리해둠\n",
    "nx.draw_networkx_labels(\n",
    "        G, pos, font_family='BM JUA_OTF', font_color='black', font_size=20, #font_weight='bold'\n",
    "    )\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../assets/images/markdown_img/180807_centrality_deg_bet_net.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_node('A')\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_shape='o', node_size=2000, \n",
    "                       node_color=['Red' if n is 'A' else 'pink'  for n in G.nodes()]\n",
    "                      )\n",
    "nx.draw_networkx_edges(G, pos, width=2)\n",
    "## font family에는 font_name이 들어가야 함. 블로그에 정리해둠\n",
    "nx.draw_networkx_labels(\n",
    "        G, pos, font_family='BM JUA_OTF', font_color='black', font_size=20, #font_weight='bold'\n",
    "    )\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../assets/images/markdown_img/180807_centrality_deg_bet_net.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.remove_node('K')\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_shape='o', node_size=2000, \n",
    "                       node_color='pink'\n",
    "                       #node_color=['Red' if n is 'A' else 'pink'  for n in G.nodes()]\n",
    "                      )\n",
    "nx.draw_networkx_edges(G, pos, width=2)\n",
    "## font family에는 font_name이 들어가야 함. 블로그에 정리해둠\n",
    "nx.draw_networkx_labels(\n",
    "        G, pos, font_family='BM JUA_OTF', font_color='black', font_size=20, #font_weight='bold'\n",
    "    )\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../assets/images/markdown_img/180807_centrality_deg_bet_net.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## degree centrality \n",
    "sorted(list(nx.degree_centrality(max_size_subG).items()), key=lambda x: x[1], reverse=True)[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  centrality \n",
    "sorted(list(nx.betweenness_centrality(max_size_subG).items()), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 빈도상 순위와 비교 \n",
    "#cumsum_df = pd.DataFrame(Counter(itertools.chain.from_iterable(raw_df.people)).most_common(), columns=['people', 'count'])\n",
    "cumsum_df[cumsum_df['people']=='한은지']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_rank = sorted(list(nx.degree_centrality(max_size_subG).items()), key=lambda x: x[1], reverse=True)\n",
    "bet_rank = sorted(list(nx.betweenness_centrality(max_size_subG).items()), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### deg\n",
    "tempG = max_size_subG.copy()\n",
    "max_g_size_change_lst_deg = []\n",
    "for i in range(0, 20):\n",
    "    tempG.remove_node(deg_rank[i][0])\n",
    "    all_comp = list(nx.connected_component_subgraphs(tempG))\n",
    "    subgroup_count = len(all_comp)\n",
    "    max_g_size_change_lst_deg.append(len(max(all_comp, key=lambda x: len(x.nodes())).nodes()))\n",
    "    #print(subgroup_count, max_subgroup_count)\n",
    "##### bet\n",
    "tempG = max_size_subG.copy()\n",
    "max_g_size_change_lst_bet = []\n",
    "for i in range(0, 20):\n",
    "    tempG.remove_node(bet_rank[i][0])\n",
    "    all_comp = list(nx.connected_component_subgraphs(tempG))\n",
    "    subgroup_count = len(all_comp)\n",
    "    max_g_size_change_lst_bet.append(len(max(all_comp, key=lambda x: len(x.nodes())).nodes()))\n",
    "    #print(subgroup_count, max_subgroup_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(max_g_size_change_lst_deg, color='darkblue', linewidth=3, linestyle=':',\n",
    "         label='deg가 높은 node를 제거')\n",
    "plt.plot(max_g_size_change_lst_bet, color='crimson', linewidth=3, linestyle='--',\n",
    "         label='bet가 높은 node를 제거')\n",
    "plt.scatter(5, max_g_size_change_lst_bet[5], marker='h', color='red', s=500, zorder=5, )\n",
    "plt.annotate('bet가 높은 node를 자르다보면 \\n가장 큰 네트워크의 크기가 확 줄어듬', ## 텍스트\n",
    "             xy=(5, max_g_size_change_lst_bet[5]), xytext=(8, 500),\n",
    "             fontsize=20, fontproperties=BMDOHYEON, \n",
    "             arrowprops=dict(facecolor='red', edgecolor='black', shrink=0.1, \n",
    "                             headwidth=30,headlength=20, width=10, linewidth=5, alpha=0.8, )\n",
    "            )\n",
    "## \n",
    "plt.legend(prop={'family':BMJUA.get_name(), 'size':20})\n",
    "plt.xticks(fontproperties=BMJUA, fontsize=15), plt.yticks(fontproperties=BMJUA, fontsize=15)\n",
    "plt.title('centrality가 높은 node를 순차적으로 제거했을 때 가장 큰 네트워크의 크기 변화', fontproperties=BMJUA)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../assets/images/markdown_img/180807_remove_bet_node_change.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## betweenness cent가 높은 edge를 잘라가면서 클러스터를 분리합니다. \n",
    "tempG = max_size_subG.copy()\n",
    "bet_cent_edges = sorted((it for it in nx.edge_betweenness_centrality(tempG).items()), key=lambda x: x[1], reverse=True)\n",
    "for i, edge in enumerate(bet_cent_edges):\n",
    "    if len(list(nx.connected_component_subgraphs(tempG)))<=200:\n",
    "        tempG.remove_edge(*edge[0])\n",
    "    else:\n",
    "        print(i)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community\n",
    "coverage_lst = []\n",
    "performance_lst = []\n",
    "## 적절한 cluster 값을 어떻게 찾지\n",
    "for i in range(3, 200):\n",
    "    coverage_lst.append(\n",
    "        community.coverage(max_size_subG, list(community.asyn_fluidc(max_size_subG, i)))\n",
    "    )\n",
    "    performance_lst.append(\n",
    "        community.performance(max_size_subG, list(community.asyn_fluidc(max_size_subG, i)))\n",
    "    )\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(coverage_lst)\n",
    "plt.plot(performance_lst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 가장 높은 edge betweeness centrality를 잘라가면서 클러스터를 만들어 가는 것. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = community.girvan_newman(G)\n",
    "len(list(communities))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 테스트 그래프 생성\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from([chr(c) for c in range(ord('A'), ord('A')+15)])\n",
    "# add edge\n",
    "G.add_edges_from([('A', n) for n in list(G.node())[:10]])\n",
    "G.add_edges_from([('G', n) for n in list(G.node())[11:]])\n",
    "G.add_edges_from([('B', 'J'), ('C', 'J'), ('C', 'H'), ('H', 'E'), ('E', 'D'), ('D', 'I'), \n",
    "                  ('I', 'F'), ('B', 'K'), ('K', 'F')])\n",
    "G.add_edges_from([('O', 'N'), ('N', 'L'), ('M', 'L'), ('O', 'K'), ('K', 'M')])\n",
    "G.add_edges_from([('A', 'K'), ('G', 'K')])\n",
    "G.remove_edge('A', 'G'), \n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "#G.remove_node('K')\n",
    "#G.remove_nodes_from(['A', 'G'])\n",
    "####\n",
    "## edge betweeness가 높은 centrality를 잘라보면서 클러스터가 바뀌는지를 확인 \n",
    "nx.edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## edge의 betweeness centrality가 높은 것을 cmap에 따라서 색깔로 다르게 표현할 수 있나. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_shape='o', node_size=2000, node_color='pink')\n",
    "nx.draw_networkx_edges(G, pos, width=2)\n",
    "## font family에는 font_name이 들어가야 함. 블로그에 정리해둠\n",
    "nx.draw_networkx_labels(\n",
    "        G, pos, font_family='BM JUA_OTF', font_color='black', font_size=20, #font_weight='bold'\n",
    "    )\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('../../assets/images/markdown_img/180807_centrality_deg_bet_net.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clique 찾기 \n",
    "## clique를 다시 조합하여 그래프로 보여주면 좋겠는데 \n",
    "## \n",
    "tempG = max_size_subG.copy()\n",
    "\n",
    "## 일정 weight가 안되는 node는 삭제함\n",
    "tempG.remove_edges_from([(e[0], e[1]) for e in list(tempG.edges(data=True)) if e[2]['weight']<20])\n",
    "#max_size_subG.nodes(data=True)\n",
    "## 존재하는 모든 clique 찾기\n",
    "all_clique = nx.find_cliques(tempG)\n",
    "all_clique = filter(lambda x: True if len(x)>=4 else False, all_clique)\n",
    "all_clique = sorted(all_clique, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "all_clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(list(map(lambda x: x[2]['weight'], list(tempG.edges(data=True)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tempG = max_size_subG.copy()\n",
    "[(e[0], e[1]) for e in list(tempG.edges(data=True)) if e[2]['weight']>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_count_df = pd.DataFrame(Counter(itertools.chain.from_iterable(raw_df.people)).most_common(), columns=['people', 'count'])\n",
    "print(\"\\n\".join(list(p_count_df.people)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
