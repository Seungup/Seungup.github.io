{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "\n",
    "train_df = pd.read_csv(\"https://storage.googleapis.com/kaggle-competitions-data/kaggle/3004/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1527922704&Signature=ABIBMpRUAsvD97%2FpOGe0Ch7%2F3ytIrGGgLrSIRkv6Q2X5%2BRaiueFBRSRuCUdiVIqeHa4sXdD0ML37qI0ybx%2FaS5Z3NnYWj9N2c6%2B6JYzjl12ebZzrqblAPXDjBiIVSNO6ygiV4i9GBwn0cQB1cZtysQhsWUtAqPmfgnXnepmbvcmDn2kG78qFxhkNm78Opva52vigptri%2F08byHP7DTgEB6778%2FKSAwdJw5nHH8nj9M7x263mqj01ct6D0o5PLpV%2FbGSQf8kZM3q5kGT1KhaIbh%2FAtz2wAN4brFtB%2Fvznyvbuqx%2BK%2FWR%2FGSvYnQ1AaRcWwHeMCRpCmIgT2dfCq29WLQ%3D%3D\") \n",
    "test_df = pd.read_csv(\"https://storage.googleapis.com/kaggle-competitions-data/kaggle/3004/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1527922522&Signature=R%2BCLwbq0LUF5tZ%2BowcWPnJOTfkCo5xNB%2BxQNFoAPlsrqyM8PanUsgU3%2FcfFrMv86U6oMHsWup2vuVjD61ekG8NphsiEEFamBb3whTaA%2BdEBVdL2cscyaES4sJPAIGTU1x%2BYcsvjbGuxdFR8y6oi31Ar42pAicoW%2B0lz1HLeQeo86lksOaj3fXjRqWKWD34rqNqKt04HoYepzOgSZqI4hAFHoAyoT%2F4oC7Nx%2BakA4mJTzOCs%2BmlH4z08SsevZ%2BBnvqZGrS3NfquqxhyFONfL6lPOH8cr1%2BxiaT1E5tTqs74Zo%2BKbQLJp6so1QGNI89UFl6NiVIZFPhULeXZ7%2BatpiZw%3D%3D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_size: [10, 10]\n",
      "train accuracy: 91.27%, test accuracy: 88.73%\n",
      "-----------------\n",
      "hidden_layer_size: [10, 20, 10]\n",
      "train accuracy: 94.61%, test accuracy: 91.24%\n",
      "-----------------\n",
      "hidden_layer_size: [10, 80, 240, 80, 10]\n",
      "train accuracy: 96.34%, test accuracy: 92.65%\n",
      "-----------------\n",
      "hidden_layer_size: [10, 20, 40, 80, 40, 20, 10]\n",
      "train accuracy: 96.73%, test accuracy: 92.60%\n",
      "-----------------\n",
      "hidden_layer_size: [10, 20, 40, 80, 160, 80, 40, 20, 10]\n",
      "train accuracy: 96.98%, test accuracy: 93.29%\n",
      "-----------------\n",
      "hidden_layer_size: [10, 80, 240, 960, 240, 80, 10]\n",
      "train accuracy: 96.83%, test accuracy: 92.52%\n",
      "-----------------\n",
      "hidden_layer_size: [10, 80, 240, 480, 960, 480, 240, 80, 10]\n",
      "train accuracy: 93.98%, test accuracy: 90.95%\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def print_accuracy(clf):\n",
    "    X = train_df[train_df.columns[1:]]\n",
    "    Y = train_df['label']\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state=42)\n",
    "    train_sample_size = len(x_train)\n",
    "    x_train = x_train[x_train.columns][:train_sample_size]\n",
    "    y_train = y_train[:train_sample_size]\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    print(\"train accuracy: {:.2%}, test accuracy: {:.2%}\".format(\n",
    "        accuracy_score(y_train, clf.predict(x_train)),\n",
    "        accuracy_score(y_test, clf.predict(x_test))\n",
    "    ))\n",
    "hidden_layer_size_lst = [\n",
    "    [10, 10], \n",
    "    [10, 20, 10],\n",
    "    [10, 80, 240, 80, 10],\n",
    "    [10, 20, 40, 80, 40, 20, 10],\n",
    "    [10, 20, 40, 80, 160, 80, 40, 20, 10],\n",
    "    [10, 80, 240, 960, 240, 80, 10],\n",
    "    [10, 80, 240, 480, 960, 480, 240, 80, 10],\n",
    "]\n",
    "for h_l_s in hidden_layer_size_lst:\n",
    "    print(\"hidden_layer_size: {}\".format(h_l_s))\n",
    "    print_accuracy( MLPClassifier(hidden_layer_sizes=h_l_s, activation='relu', solver='adam') )\n",
    "    print(\"-----------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29400,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15s - loss: 0.4710 - categorical_accuracy: 0.8643\n",
      "Epoch 2/10\n",
      "11s - loss: 0.1379 - categorical_accuracy: 0.9584\n",
      "Epoch 3/10\n",
      "12s - loss: 0.0792 - categorical_accuracy: 0.9766\n",
      "Epoch 4/10\n",
      "11s - loss: 0.0557 - categorical_accuracy: 0.9830\n",
      "Epoch 5/10\n",
      "11s - loss: 0.0372 - categorical_accuracy: 0.9884\n",
      "Epoch 6/10\n",
      "10s - loss: 0.0263 - categorical_accuracy: 0.9914\n",
      "Epoch 7/10\n",
      "11s - loss: 0.0210 - categorical_accuracy: 0.9934\n",
      "Epoch 8/10\n",
      "12s - loss: 0.0184 - categorical_accuracy: 0.9941\n",
      "Epoch 9/10\n",
      "12s - loss: 0.0123 - categorical_accuracy: 0.9961\n",
      "Epoch 10/10\n",
      "11s - loss: 0.0077 - categorical_accuracy: 0.9973\n",
      "train, loss and metric: [0.0042793890967455115, 0.99892857142857139]\n",
      "test, loss and metric: [0.098965269476175302, 0.97619047630400879]\n",
      "<keras.callbacks.History object at 0x1a55c51f60>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- keras에서는 Y를 one_hot vector로 바꾸어 사용해야 함\n",
    "- X의 값들이 0과 256 사이에 분포해있으므로, 이를 0과 1.0 사이로 움직임 \n",
    "- train, test set으로 구분하여 진행\n",
    "\"\"\"\n",
    "X = train_df[train_df.columns[1:]]\n",
    "Y = pd.get_dummies(train_df['label'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(X.values.astype(np.float64)/256.0, \n",
    "                                                    Y.values.astype(np.float32), \n",
    "                                                    test_size = 0.2, random_state=42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import metrics\n",
    "\"\"\"\n",
    "- 원래 데이터가 784이므로, 비슷한 1024로 두고 이를 감소시키는 뉴럴넷 설계\n",
    "- 총 10개로 클래스를 구분하므로, 마지막 Dense는 10개의 노드를 가지고 있어야함\n",
    "- 그리고, 마지막은 softmax\n",
    "\"\"\"\n",
    "model = Sequential([\n",
    "    Dense(1024, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(512),\n",
    "    Activation('relu'),\n",
    "    Dense(256),\n",
    "    Activation('relu'),\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dense(32),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\"\"\"\n",
    "- multi classification이므로 loss는 'categorical_crossentropy'\n",
    "- metric에는 내가 추적할 지표들이 들어감. 최적화는 loss에 따라 되는데, epoch 마다 평가될 지표들이 metric에 들어감. \n",
    "\"\"\"\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              #optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8),\n",
    "              metrics=[metrics.categorical_accuracy])\n",
    "\"\"\"\n",
    "- one epoch = one forward pass and one backward pass of all the training examples\n",
    "- batch size = the number of training examples in one forward/backward pass. \n",
    "\n",
    "- 즉, epoch을 증가한다는 것은 전체 데이터 셋을 몇 번 돌릴 것이냐 를 결정하는 것이고, \n",
    "- batch_size는 backpropagation을 몇 개의 size로 돌릴 것이냐? 를 결정하는 이야기다.\n",
    "\"\"\"\n",
    "train_history = model.fit(x_train, y_train, epochs=10, batch_size=500, verbose=2)\n",
    "# 아래 세 줄은 필요없는 코드인데, 그래도 이후에 평가할때 사용될 수 있어서 일단 넣어둠. \n",
    "y_predict = model.predict_classes(x_train, verbose=0)\n",
    "y_true = [ np.argmax(y) for y in y_train]\n",
    "accuracy = np.sum([y_comp[0]==y_comp[1] for y_comp in zip(y_predict, y_true)])\n",
    "\n",
    "loss_and_metric = model.evaluate(x_train, y_train, batch_size=128, verbose=0)\n",
    "print(\"train, loss and metric: {}\".format(loss_and_metric))\n",
    "loss_and_metric = model.evaluate(x_test, y_test, batch_size=128, verbose=0)\n",
    "print(\"test, loss and metric: {}\".format(loss_and_metric))\n",
    "\n",
    "print(train_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categorical_accuracy': [0.86434523812273434,\n",
       "  0.95839285282861619,\n",
       "  0.97657738164776853,\n",
       "  0.98297619287456783,\n",
       "  0.98836309569222591,\n",
       "  0.99142856647570932,\n",
       "  0.99336309872922446,\n",
       "  0.99413690751507167,\n",
       "  0.99607143355976968,\n",
       "  0.99729167847406297],\n",
       " 'loss': [0.47096433277641025,\n",
       "  0.13793105441367343,\n",
       "  0.079229129012674093,\n",
       "  0.055743424953626733,\n",
       "  0.037167249535698263,\n",
       "  0.026272059800768539,\n",
       "  0.020952539687554929,\n",
       "  0.018360651821283335,\n",
       "  0.012266367429956085,\n",
       "  0.0077410289290821225]}"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
