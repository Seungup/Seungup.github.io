{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from gym.envs.registration import register\n",
    "# 아래의 방식을 통해 게임을 등록함. 특히 is_slippery는 매우 중요함. \n",
    "\"\"\"\n",
    "- 새로운 게임 형식을 만들어줌.\n",
    "\"\"\"\n",
    "register(\n",
    "    id='FrozenLakeNotSlippery-v1',\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
    "    #max_episode_steps=100,\n",
    "    #reward_threshold=0.78, # optimum = .8196\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FH\u001b[41mF\u001b[0mH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "done, reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLakeNotSlippery-v1\")\n",
    "observation = env.reset()\n",
    "\n",
    "\"\"\"\n",
    "0: left, 1: down, 2: right, 3: up \n",
    "\"\"\"\n",
    "for i in range(0, 1):\n",
    "    action = env.action_space.sample()# randomly select action \n",
    "    \"\"\"\n",
    "    - new_state: 액션을 취해서 새롭게 옮겨진 위치 \n",
    "    - reward: 보상을 얻었는지 여부\n",
    "    - done: 게임이 끝났는지 여부(hole에 빠지거나, )\n",
    "    \"\"\"\n",
    "    new_state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "#####\n",
    "##\n",
    "env = gym.make(\"FrozenLakeNotSlippery-v1\")\n",
    "observation = env.reset()\n",
    "complete_actions = [2, 2, 1, 1, 1, 2]\n",
    "for action in actions:\n",
    "    new_state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    if done is True:\n",
    "        print(\"done, reward: {}\".format(reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAACPCAYAAADugo3xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nifjbpQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a151a4ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "- 사실 이런 형태의 미로에서는 reward를 끝나봐야 얻습니다. 끝날때까지 reward가 어디있는지 모른다는 이야기죠. \n",
    "- 비슷하게, 장기 바둑도 마찬가지입니다. 이전의 어떤 수가 reward를 결정했는지는 알기가 어려우니까요.\n",
    "- 아무튼, 그러므로, dummy Q-learning algorithm에서는 t+1 state의 reward의 max값을 t state의 reward의 max 값으로 정합니다. \n",
    "    - 미래의 리워드를 현재의 리워드로 가져온다는 말이 이상하지만, 이걸 정리하면, \"이번 게임에서 t+1 스텝\n",
    "\"\"\"\n",
    "def rargmax_new(vector):\n",
    "    \"\"\"\n",
    "    max가 여러 개 있을 경우, 그중에서 random 하게 고름\n",
    "    \"\"\"\n",
    "    m = vector.max() \n",
    "    indices = [i for i, v in enumerate(vector==m) if v==True]\n",
    "    return np.random.choice(indices)\n",
    "# how to is slippely false\n",
    "env = gym.make(\"FrozenLakeNotSlippery-v1\")\n",
    "observation = env.reset()\n",
    "\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "num_episodes = 200 # 일종의 epoch, 혹은 라이프.\n",
    "\n",
    "rlist = []\n",
    "for i in range(0, num_episodes):\n",
    "    state = env.reset()\n",
    "    e = 1. / (i/100)+1 \n",
    "    \"\"\"\n",
    "    goal에 이르는 답이 여러가지일 수 있는데, \n",
    "    \"\"\"\n",
    "    #env.render()\n",
    "    rAll = 0 # 한 episode 별로 얻을 수 있는 reward의 총합\n",
    "    done = False # hole에 빠지거나, Goal에 도달하면 True\n",
    "    while not done:\n",
    "        action = rargmax_old(Q[state, :]) # randomg among maximum\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        Q[state, action] = reward + 0.8*np.max(Q[new_state, :])\n",
    "        rAll+=reward\n",
    "        state = new_state # state update\n",
    "    rlist.append(rAll)\n",
    "print('complete')\n",
    "\n",
    "\"\"\"\n",
    "- 처음에는 잘 못 맞추다가, 한 두번 맞추기 시작하면서 부터는 슥슥 매우 잘 맞춤\n",
    "- 그냥 random으로 시행할 경우에는, 1.3%의 확률로 reward 획득\n",
    "\"\"\"\n",
    "plt.figure(figsize=(12, 2))\n",
    "plt.scatter(range(0, len(rlist)), rlist, marker='^', s=1, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01315"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
