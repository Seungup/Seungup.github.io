{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,705\n",
      "Trainable params: 856,065\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "## create generator \n",
    "generator_ = Sequential([\n",
    "    Dense(128 * 7 * 7, activation=\"relu\", input_shape=(100,)), \n",
    "    Reshape((7, 7, 128)), \n",
    "    \n",
    "    BatchNormalization(momentum=0.8), # what is batch normalization?? \n",
    "    UpSampling2D(), # what is upsampling?? \n",
    "    Conv2D(128, kernel_size=3, padding=\"same\"),\n",
    "    Activation(\"relu\"), \n",
    "    \n",
    "    BatchNormalization(momentum=0.8), \n",
    "    UpSampling2D(), \n",
    "    Conv2D(64, kernel_size=3, padding=\"same\"), \n",
    "    Activation(\"relu\"), \n",
    "    \n",
    "    BatchNormalization(momentum=0.8), \n",
    "    Conv2D(1, kernel_size=3, padding=\"same\"), \n",
    "    Activation(\"tanh\"), \n",
    "])\n",
    "\n",
    "noise_input = Input(shape=(100,), name=\"noise_input\")\n",
    "generator = Model(noise_input, generator_(noise_input), name=\"generator\")\n",
    "\n",
    "generator_.summary()# summary가 매우 유용하군요. \n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_51 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 392,705\n",
      "Trainable params: 392,321\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### create discriminator\n",
    "discriminator_ = Sequential([\n",
    "    Conv2D(32, kernel_size=3, strides=2, input_shape=(28, 28, 1), padding=\"same\"), \n",
    "    LeakyReLU(alpha=0.2), \n",
    "    Dropout(0.25), \n",
    "    \n",
    "    Conv2D(64, kernel_size=3, strides=2, padding=\"same\"), \n",
    "    ZeroPadding2D(padding=((0,1),(0,1))), \n",
    "    LeakyReLU(alpha=0.2), \n",
    "    Dropout(0.25), \n",
    "    BatchNormalization(momentum=0.8), \n",
    "    \n",
    "    Conv2D(128, kernel_size=3, strides=2, padding=\"same\"), \n",
    "    LeakyReLU(alpha=0.2), \n",
    "    Dropout(0.25), \n",
    "    BatchNormalization(momentum=0.8), \n",
    "    \n",
    "    Conv2D(256, kernel_size=3, strides=1, padding=\"same\"), \n",
    "    LeakyReLU(alpha=0.2), \n",
    "    Dropout(0.25), \n",
    "    Flatten(), \n",
    "    Dense(1, activation='sigmoid'), \n",
    "])\n",
    "image_input = Input(shape=(28, 28, 1), name=\"image_input\")\n",
    "\n",
    "discriminator = Model(image_input, discriminator_(image_input), name=\"discriminator\")\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "discriminator_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combined Model\n",
    "noise_input2 = Input(shape=(100,), name=\"noise_input2\")\n",
    "\"\"\"\n",
    "model과 sequential의 차이는?? \n",
    "가설1: 레이어를 쌓는 것이 sequential 이라면, sequential을 쌓는 것이 model인가???\n",
    "\n",
    "1) 다음 모델의 경우는 랜덤으로 만든 이미지로부터 학습해서 새로운 이미지를 만들어내는 generator의 데이터를 \n",
    "2) discriminator가 분류하는 형식으로 진행된다. \n",
    "\"\"\"\n",
    "combined = Model(noise_input2, discriminator(generator(noise_input2)))\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read image\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_data = np.random.normal(0, 1, (32, 100))\n",
    "generated_images = 0.5 * generator.predict(noise_data) + 0.5\n",
    "\n",
    "def show_images(generated_images, n=4, m=8, figsize=(9, 5)):\n",
    "    f, axes = plt.subplots(n, m, figsize=figsize)\n",
    "    #plt.subplots_adjust(top=1, bottom=0, hspace=0, wspace=0.05)\n",
    "    for i in range(0, n):\n",
    "        for j in range(0, m):\n",
    "            ax = axes[i][j]\n",
    "            ax.imshow(generated_images[i * m + j][:, :, 0], cmap=plt.cm.bone)\n",
    "            ax.grid(False)\n",
    "            ax.xaxis.set_ticks([])\n",
    "            ax.yaxis.set_ticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../../assets/images/markdown_img/180621_1554_gan_digit_img.svg')\n",
    "    plt.show()   \n",
    "#show_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 [D loss: 0.824, acc.: 50.39%] [G loss: 0.639, acc.: 64.84%]\n",
      "   10 [D loss: 0.050, acc.: 99.61%] [G loss: 0.007, acc.: 100.00%]\n",
      "   20 [D loss: 0.389, acc.: 82.42%] [G loss: 0.004, acc.: 100.00%]\n",
      "   30 [D loss: 2.457, acc.: 47.27%] [G loss: 0.229, acc.: 96.48%]\n",
      "   40 [D loss: 2.456, acc.: 49.61%] [G loss: 0.218, acc.: 98.44%]\n",
      "   50 [D loss: 2.250, acc.: 50.00%] [G loss: 0.202, acc.: 100.00%]\n",
      "   60 [D loss: 2.086, acc.: 50.00%] [G loss: 0.196, acc.: 100.00%]\n",
      "   70 [D loss: 2.074, acc.: 50.00%] [G loss: 0.196, acc.: 100.00%]\n",
      "   80 [D loss: 1.972, acc.: 50.00%] [G loss: 0.191, acc.: 99.61%]\n"
     ]
    }
   ],
   "source": [
    "## training\n",
    "\"\"\"\n",
    "- 이 코드에서는 fit을 사용한 것이 아니라, train_on_batch를 사용했음. \n",
    "- train_on_batch와의 차이점?을 구글에 검색해보니, 큰 차이가 없다고 하긴 하는데\n",
    "    - train_on_batch의 경우, 넘겨 받은 데이터에 대해서 gradient vector를 계산해서 적용하고 끝내는 것이고(1epoch)\n",
    "    - fit의 경우는 epoch과 batch_size를 한번에 모두 넘겨준다는 것 정도가 차이가 된다. \n",
    "- GAN의 경우, discriminator의 학습시 마다 generator가 생성하는 데이터가 변화하게 된다. \n",
    "    - 즉 처음부터 모든 데이터가 존재하고 이를 한번에 학습시키는 fit과는 다르게, 한번씩 업데이트를 할때마다 모델이 변화하므로, \n",
    "    - train_on_batch를 사용하는 것이 매우 합당함.\n",
    "\"\"\"\n",
    "batch_size = 256\n",
    "half_batch = batch_size // 2\n",
    "\n",
    "def train(epochs, print_step=10):\n",
    "    history = []\n",
    "    for epoch in range(epochs):\n",
    "        # discriminator 트레이닝 단계\n",
    "        #######################################################################3\n",
    "        # 데이터 절반은 실제 이미지, 절반은 generator가 생성한 가짜 이미지\n",
    "        # discriminator가 실제 이미지와 가짜 이미지를 구별하도록 discriminator를 트레이닝\n",
    "        discriminator.trainable = True\n",
    "        d_loss_real = discriminator.train_on_batch(X_train[np.random.randint(0, X_train.shape[0], half_batch)], \n",
    "                                                   np.ones((half_batch, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(generator.predict(np.random.normal(0, 1, (half_batch, 100))), \n",
    "                                                   np.zeros((half_batch, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        # generator 트레이닝 단계\n",
    "        #######################################################################3\n",
    "        # 전부 generator가 생성한 가짜 이미지를 사용. \n",
    "        # discriminator가 구별하지 못하도록 generator를 트레이닝\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        discriminator.trainable = False \n",
    "        \"\"\"\n",
    "        generator를 트레이닝할 때는, 반드시 discriminator가 필요함. \n",
    "        generator가 만든 image를 평가해야 하고, 그래야 feedback이 생겨서 generator가 학습됨. \n",
    "        따라서, generator는 combined model을 통해 학습시키는데, 이때, discriminator도 함께 학습되면 안되기 때문에\n",
    "        discriminator.trainable 을 False로 변경시켜 둔다. \n",
    "        \"\"\"\n",
    "        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "        # 기록\n",
    "        record = (epoch, d_loss[0], 100 * d_loss[1], g_loss[0], 100 * g_loss[1])\n",
    "        history.append(record)\n",
    "        if epoch % print_step == 0:\n",
    "            print(\"%5d [D loss: %.3f, acc.: %.2f%%] [G loss: %.3f, acc.: %.2f%%]\" % record)\n",
    "    return history\n",
    "#%%time, 은\n",
    "history100 = train(100, 10)\n",
    "show_images(0.5 * generator.predict(noise_data) + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
