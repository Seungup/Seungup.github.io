{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df = pd.read_csv(\"https://storage.googleapis.com/kaggle-competitions-data/kaggle/5407/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1528096567&Signature=kkMTTBCgUIArj3bzZf1b%2FVDzL8TmYoKQ%2Ft%2F1i50vu4vfICWTiytExYNVqyr%2BANBvD0m6LW7DuCf5z3UfxIzemblU6jm7JGJ7NHD3Px0mrlFJB7FGJjh0BAgZmtscB4sxIi%2BoQz5BxGwWBX7ZGGfzjY3cxwjCHr1wCh6ZdVyiOYsDtf5GjdViCGOSz8g8WQj%2B%2F11PnYUcIOGAZiFeZshTXv%2Fn5KapDCjeDQ67PCiGFK0eSfvtEfkmx23Ovcbdy9D9z%2FH0W2OKVnYr0xT6XO4S2m3HaA%2BW4tV8RvEHEq4NgPLFcdyUQR8Iepn9g78Bex46BjW%2BA8vyjcJaykf6W6Ne9g%3D%3D\")\n",
    "test_df = pd.read_csv(\"https://storage.googleapis.com/kaggle-competitions-data/kaggle/5407/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1528096640&Signature=X6nHvyCS1XANFRoDPSGj3kEVJg2GA0poVeCYtk1POpPpXuGm3t%2BtqKhvjMlKrdqcJL4HA%2BCd9F0JOZCHDAPcD0VWi5wPMf288dxtU6%2BsoHuU9qY78wz84U%2B1zuESWJ%2FvhLklXx8%2B%2FCPADpk%2BEGPjHe3UMNzxruMiS7hYOZ%2ForydIr4PA78j9bXS83Vnq8dcwX1XVomcTjL4DRywAYRY39dK%2FwwZLaUvz5iERMH3DvDheLbc0O%2BG41caaq0ZLFFrob3SwATj751ubE1M1GaZ%2FF3fi8r0%2B5AA7gA6GN%2F4kABBW1qafCSlnrAz2ZWPUkceXFcsvwrqNJtc3PlxeSCTSsg%3D%3D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice        1.000000\n",
       "OverallQual      0.790982\n",
       "GrLivArea        0.708624\n",
       "GarageCars       0.640409\n",
       "GarageArea       0.623431\n",
       "TotalBsmtSF      0.613581\n",
       "1stFlrSF         0.605852\n",
       "FullBath         0.560664\n",
       "TotRmsAbvGrd     0.533723\n",
       "YearBuilt        0.522897\n",
       "YearRemodAdd     0.507101\n",
       "GarageYrBlt      0.486362\n",
       "MasVnrArea       0.477493\n",
       "Fireplaces       0.466929\n",
       "BsmtFinSF1       0.386420\n",
       "LotFrontage      0.351799\n",
       "WoodDeckSF       0.324413\n",
       "2ndFlrSF         0.319334\n",
       "OpenPorchSF      0.315856\n",
       "HalfBath         0.284108\n",
       "LotArea          0.263843\n",
       "BsmtFullBath     0.227122\n",
       "BsmtUnfSF        0.214479\n",
       "BedroomAbvGr     0.168213\n",
       "ScreenPorch      0.111447\n",
       "PoolArea         0.092404\n",
       "MoSold           0.046432\n",
       "3SsnPorch        0.044584\n",
       "BsmtFinSF2      -0.011378\n",
       "BsmtHalfBath    -0.016844\n",
       "MiscVal         -0.021190\n",
       "Id              -0.021917\n",
       "LowQualFinSF    -0.025606\n",
       "YrSold          -0.028923\n",
       "OverallCond     -0.077856\n",
       "MSSubClass      -0.084284\n",
       "EnclosedPorch   -0.128578\n",
       "KitchenAbvGr    -0.135907\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "corr이 높은 순으로 넣어보자. \n",
    "\"\"\"\n",
    "train_df.corr()['SalePrice'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['OverallQual'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet\n",
      "train score: 0.869\n",
      "mse: 0.020858482391253697\n",
      "----------\n",
      "rf1\n",
      "train score: 0.974\n",
      "mse: 0.004188170882879435\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\"\"\"\n",
    "data exploration 을 해야 하는데, \n",
    "- numerical categorical 분류하고, \n",
    "- correlation matrix를 뽑아보자. \n",
    "\"\"\"\n",
    "def preprocessingX(input_df):\n",
    "    X = input_df[['OverallQual', 'OverallCond', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath',\n",
    "                  'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'MasVnrArea', 'Fireplaces', 'YrSold',\n",
    "                  'BsmtFinSF1', 'LotFrontage', 'WoodDeckSF', '2ndFlrSF', 'OpenPorchSF', 'HalfBath', 'LotArea'\n",
    "             ]]\n",
    "    for col in ['SaleCondition', 'SaleType', 'Street', 'BldgType', 'Condition1', 'ExterQual', 'ExterCond',\n",
    "                'Functional'\n",
    "               ]:\n",
    "        X = X.join(pd.get_dummies(input_df[col], prefix=col))\n",
    "    X = X.fillna(X.mean())\n",
    "    X = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)\n",
    "    return X\n",
    "X = preprocessingX(train_df)\n",
    "notX = train_df[ list(set(train_df.columns) - set(X.columns)) ]\n",
    "Y = np.log(train_df['SalePrice'])\n",
    "\n",
    "\n",
    "#train_x, test_x, train_y, test_y = train_test_split(X, Y, train_size=0.7, test_size=0.3, random_state=42)\n",
    "\n",
    "models = {\n",
    "    #'linreg': GridSearchCV( LinearRegression(), {}),\n",
    "    #'Ridge': GridSearchCV(Ridge(), {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]}),\n",
    "    #'Lasso': GridSearchCV(Lasso(), {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]}),\n",
    "    'ElasticNet': GridSearchCV(ElasticNet(), {'alpha':[0.001, 0.01, 0.1, 0.5, 1.0]}, cv=3),\n",
    "    'rf1': GridSearchCV(RandomForestRegressor(), {'n_estimators':[2, 5, 10]}, cv=3),\n",
    "    'rf2': GridSearchCV(RandomForestRegressor(), {'n_estimators':[20, 50]}, cv=3)\n",
    "}\n",
    "\"\"\"\n",
    "    'MLPRegressor': GridSearchCV(MLPRegressor(), {'hidden_layer_sizes':[[10, 20, 10], [10, 10, 10, 10],\n",
    "                                                                        #[32, 128, 256, 128, 32, 2]\n",
    "                                                                       ],\n",
    "                                              'activation':['relu', 'logistic'], 'solver':['adam']\n",
    "                                             }),\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for k, m in models.items():\n",
    "    m.fit(X, Y)\n",
    "    print(k)\n",
    "    print(\"train score: {:.3f}\".format(m.score(X, Y)))\n",
    "    print(\"mse: {}\".format(mean_squared_error(Y, m.predict(X))))\n",
    "    print(\"----------\")\n",
    "# notX.corr()['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "\n",
    "best_model = sorted([m for k, m in models.items()], key=lambda m: m.score(X,Y))[-1]\n",
    "#print(best_model)\n",
    "\n",
    "for r in np.linspace(0.0, 1.0, 10):\n",
    "    y_pred = models['rf1'].predict(X)*r + models['rf2'].predict(X)*(1-r)\n",
    "    print(mean_squared_error(Y, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame({'Id':test_df['Id'], \n",
    "              'SalePrice':np.exp(best_model.predict(preprocessingX(test_df)))}).to_csv(\n",
    "    \"180601_houseprice.csv\", index=False)\n",
    "print(\"complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Typ\n",
       "1        Typ\n",
       "2        Typ\n",
       "3        Typ\n",
       "4        Typ\n",
       "5        Typ\n",
       "6        Typ\n",
       "7        Typ\n",
       "8       Min1\n",
       "9        Typ\n",
       "10       Typ\n",
       "11       Typ\n",
       "12       Typ\n",
       "13       Typ\n",
       "14       Typ\n",
       "15       Typ\n",
       "16       Typ\n",
       "17       Typ\n",
       "18       Typ\n",
       "19      Min1\n",
       "20       Typ\n",
       "21       Typ\n",
       "22       Typ\n",
       "23       Typ\n",
       "24       Typ\n",
       "25       Typ\n",
       "26       Typ\n",
       "27       Typ\n",
       "28       Typ\n",
       "29       Typ\n",
       "        ... \n",
       "1430     Typ\n",
       "1431     Typ\n",
       "1432     Typ\n",
       "1433     Typ\n",
       "1434     Typ\n",
       "1435     Typ\n",
       "1436     Typ\n",
       "1437     Typ\n",
       "1438     Typ\n",
       "1439     Typ\n",
       "1440    Min1\n",
       "1441     Typ\n",
       "1442     Typ\n",
       "1443     Typ\n",
       "1444     Typ\n",
       "1445     Typ\n",
       "1446     Typ\n",
       "1447     Typ\n",
       "1448    Min2\n",
       "1449     Typ\n",
       "1450     Typ\n",
       "1451     Typ\n",
       "1452     Typ\n",
       "1453     Typ\n",
       "1454     Typ\n",
       "1455     Typ\n",
       "1456    Min1\n",
       "1457     Typ\n",
       "1458     Typ\n",
       "1459     Typ\n",
       "Name: Functional, Length: 1460, dtype: object"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "train_df['Functional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Street\n",
       "Grvl    130190.500000\n",
       "Pave    181130.538514\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notX.groupby('Hou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['HouseStyle'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notX['SaleType'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
