{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "from inflection import singularize \n",
    "import nltk\n",
    "import difflib\n",
    "\n",
    "from scipy.spatial.distance import euclidean, jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_path_and_filename = \"../../../Downloads/SMEs_Scopus_2013-2017.xlsx\"\n",
    "rawDF = pd.read_excel(excel_path_and_filename)\n",
    "df = rawDF[['Author Keywords', 'Year', 'Abstract', 'Index Keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for computation efficienty, cut down node got below weight, remaining node is 583\n",
      "solving transivity\n",
      "\n",
      "syntactically similar word를 변환해줍니다.\n",
      "keyword set size: 22883\n",
      "keyword set size: 22862\n",
      "\n",
      "series에서 weight가 8와 같거나 작은 node를 삭제합니다.\n",
      "keyword set size: 22862\n",
      "keyword set size: 746\n",
      "for computation efficienty, cut down node got below weight, remaining node is 1357\n",
      "solving transivity\n",
      "\n",
      "syntactically similar word를 변환해줍니다.\n",
      "keyword set size: 29149\n",
      "keyword set size: 29127\n",
      "\n",
      "series에서 weight가 15와 같거나 작은 node를 삭제합니다.\n",
      "keyword set size: 29127\n",
      "keyword set size: 821\n",
      "series에서 불필요한 node를 삭제합니다.\n",
      "is bipartite: True\n",
      "is connected: True\n",
      "size of cluster 0: 4\n",
      "['entrepreneurship', 'small business', 'performance', 'sustainability']\n",
      "size of cluster 1: 12\n",
      "['risk management', 'management', 'supply chain management', 'malaysia', 'development', 'project management', 'developing country', 'implementation', 'risk', 'supply chain', 'risk assessment', 'simulation']\n",
      "size of cluster 2: 8\n",
      "['technology', 'internet', 'adoption', 'social media', 'ict', 'enterprise resource planning', 'erp', 'e commerce']\n",
      "size of cluster 3: 44\n",
      "['innovation system', 'tacit knowledge', 'ecosystem', 'innovation performance', 'action research', 'evaluation', 'new product development', 'software', 'cluster', 'e learning', 'higher education', 'software process improvement', 'technology transfer', 'software engineering', 'education', 'software development', 'knowledge sharing', 'value creation', 'product development', 'design', 'information', 'creativity', 'business process', 'software quality', 'methodology', 'human resource', 'leadership', 'knowledge transfer', 'process improvement', 'training', 'requirements engineering', 'market', 'networking', 'human factor', 'prototyping', 'additive manufacturing', 'coopetition', 'vocational training', 'modeling', 'learning', 'motivation', 'process', 'knowledge management km', 'business model']\n",
      "size of cluster 5: 2\n",
      "['small and medium sized enterprise', 'sme']\n",
      "size of cluster 6: 2\n",
      "['case study', 'knowledge management']\n",
      "size of cluster 8: 16\n",
      "['firm size', 'manufacturing industry', 'strategy', 'manufacturing sme', 'empirical study', 'china', 'productivity', 'resource based view', 'competitive advantage', 'competitiveness', 'information and communication technology', 'organizational performance', 'intellectual capital', 'firm performance', 'absorptive capacity', 'information technology']\n",
      "size of cluster 9: 10\n",
      "['industrial symbiosis', 'triz', 'cleaner production', 'eco design', 'eco innovation', 'sustainable manufacturing', 'lca', 'resource efficiency', 'life cycle assessment', 'circular economy']\n",
      "size of cluster 10: 6\n",
      "['industry', 'barrier', 'energy efficiency', 'industrial energy efficiency', 'decision making', 'driver']\n",
      "size of cluster 11: 13\n",
      "['six sigma', 'lean manufacturing', 'lean production', 'automation', 'fuzzy logic', 'quality management', 'research', 'performance measurement', 'indium', 'lean', 'quality', 'industry 4 0', 'ahp']\n",
      "size of cluster 13: 42\n",
      "['business intelligence', 'internet of things', 'saas', 'web 2 0', 'big data', 'cloud', 'information system', 'sme s', 'cloud manufacturing', 'manufacturing system', 'model', 'service', 'ontology', 'critical success factor', 'knowledge', 'enterprise architecture', 'internationalization', 'integration', 'open source', 'cyber physical system', 'strategic alignment', 'framework', 'literature review', 'virtual enterprise', 'software as a service saas', 'soa', 'software as a service', 'information management', 'greece', 'uml', 'collaborative network', 'virtual factory', 'erp system', 'multi agent system', 'interoperability', 'collaborative innovation', 'open source software', 'cloud service', 'plm', 'benefit', 'standard', 'sme network']\n",
      "size of cluster 14: 4\n",
      "['collaboration', 'network', 'manufacturing', 'open innovation']\n",
      "size of cluster 16: 6\n",
      "['strategic management', 'total quality management', 'sustainable development', 'survey', 'enterprise', 'corporate social responsibility']\n",
      "size of cluster 17: 14\n",
      "['canada', 'commercialization', 'neural network', 'organizational change', 'croatia', 'intervention', 'regulation', 'work environment', 'perception', 'culture', 'network analysis', 'assessment', 'occupational health and safety', 'application']\n",
      "size of cluster 18: 39\n",
      "['planning', 'credit risk', 'e business', 'classification', 'accounting', 'outsourcing', 'entrepreneurial orientation', 'technology adoption', 'factor analysis', 'accounting information system', 'partial least square', 'australia', 'cluster analysis', 'diffusion of innovation', 'decision support system', 'information security', 'actor network theory', 'ict adoption', 'cloud erp', 'security', 'facebook', 'safety', 'economic growth', 'risk analysis', 'indonesia', 'clustering', 'business performance', 'structural equation modelling', 'business', 'compliance', 'market orientation', 'local government', 'information and communication technologies ict', 'manufacturing sector', 'data mining', 'technology acceptance model', 'sem', 'tam', 'pakistan']\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "주관적이지 않은 필터링, 아주 기본적인 filtering. \n",
    "split 부터 keyword list of list로 변환하여 리턴\n",
    "\"\"\"\n",
    "def basic_filter_Series(i_Series):\n",
    "    r_Series = i_Series.copy().fillna(\"\").apply(lambda s: s.strip().lower().split(\";\"))\n",
    "    def replace_sp_chr(input_s):\n",
    "        return \"\".join(map(lambda c: c if 'a'<=c and c<='z' else c if '0'<=c and c<='9'else \" \", input_s)).strip()\n",
    "    def remove_double_space(input_s):\n",
    "        while \"  \" in input_s:\n",
    "            input_s = input_s.replace(\"  \", \" \")\n",
    "        return input_s.strip()\n",
    "    r_Series = r_Series.apply(\n",
    "        lambda ks: list(map(\n",
    "            lambda k: remove_double_space(replace_sp_chr(k)), ks)))\n",
    "    \n",
    "    all_kwd_set = set(itertools.chain.from_iterable(list(r_Series)))\n",
    "    to_singular_dict = {}\n",
    "    for kwd in all_kwd_set:\n",
    "        singularized_kwd = singularize(kwd)\n",
    "        if singularized_kwd !=kwd and singularized_kwd in all_kwd_set:\n",
    "            to_singular_dict[kwd] = singularized_kwd\n",
    "    \"\"\"remove blank string\"\"\"\n",
    "    r_Series = r_Series.apply(lambda ks:filter(lambda k: True if k!=\"\" else False, ks))\n",
    "    \"\"\"singularize \"\"\"\n",
    "    r_Series = r_Series.apply(\n",
    "        lambda ks: sorted(list(set(map(\n",
    "            lambda k: to_singular_dict[k].strip() if k in to_singular_dict.keys() else k.strip(), ks\n",
    "        )))))    \n",
    "    return r_Series\n",
    "\"\"\"\n",
    "series로부터 그래프를 만들어주는 함수\n",
    "\"\"\"\n",
    "def make_graph_from_series(i_Series):\n",
    "    rG = nx.Graph()\n",
    "    rG.add_nodes_from(\n",
    "        (n[0], {'weight':n[1]}) for n in Counter(itertools.chain.from_iterable(i_Series)).most_common())\n",
    "    edges = []\n",
    "    for x in i_Series:\n",
    "        if len(x)!=0:\n",
    "            edges += [(x[i], x[j]) for i in range(0, len(x)-1) for j in range(i+1, len(x))]\n",
    "    rG.add_edges_from(\n",
    "        [(e[0][0], e[0][1], {'weight':e[1]}) for e in Counter(edges).most_common()])\n",
    "    return rG\n",
    "\"\"\"\n",
    "형태적으로 유사한 키워드를 찾아서 변환딕셔너리를 리턴. \n",
    "node의 weight가 above_node_w여야 하고, above_sim보다 유사도가 높아야 함\n",
    "\"\"\"\n",
    "def syntactical_simialrity_dict(i_Series, above_node_w=10, above_sim=0.9):\n",
    "    kwd_counter = itertools.chain.from_iterable(i_Series)\n",
    "    kwd_count_dct = {w:c for w, c in Counter(kwd_counter).most_common() if c >= above_node_w}\n",
    "    print(\"for computation efficienty, cut down node got below weight, remaining node is {}\".format(len(kwd_count_dct)))\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    kwd_changed_dct = {}\n",
    "    for w1 in sorted(kwd_count_dct.keys()):\n",
    "        for w2 in sorted(kwd_count_dct.keys()):\n",
    "            if w1 < w2 and w1[0]==w2[0] and \" \" in w1 and \" \" in w2:\n",
    "                \"\"\"중복을 피하고, 처음 캐릭터가 같고, 해당 단어가 복합어일 것 \n",
    "                \"\"\"\n",
    "                sim_v = difflib.SequenceMatcher(None,w1, w2).ratio()\n",
    "                if sim_v >= above_sim:\n",
    "                    if kwd_count_dct[w1] >= kwd_count_dct[w2]:\n",
    "                        kwd_changed_dct[w2]=w1\n",
    "                    else:\n",
    "                        kwd_changed_dct[w1]=w2\n",
    "    \"\"\"\n",
    "    변환 딕셔너리를 non transitive하게, a==>b, b==>c 인 형태를 a==>c, b==>c 인 형태로 바꿔줌\n",
    "    \"\"\"\n",
    "    def make_non_transitive(input_dct):\n",
    "        print('solving transivity')\n",
    "        non_transvitiy_kwd_dict = {}\n",
    "        for k, v in input_dct.items():\n",
    "            while v in input_dct.keys():\n",
    "                v = input_dct[v]\n",
    "            non_transvitiy_kwd_dict[k] = v\n",
    "        return non_transvitiy_kwd_dict\n",
    "    return make_non_transitive(kwd_changed_dct)\n",
    "\n",
    "\"\"\"\n",
    "입력받은 input_dct에 따라서 키워드를 변환하여 새로운 Series를 리턴\n",
    "\"\"\"\n",
    "def transform_by_dict(i_Series, input_dct):\n",
    "    print()\n",
    "    print(\"syntactically similar word를 변환해줍니다.\")\n",
    "    print('keyword set size: {}'.format(len(set(itertools.chain.from_iterable(i_Series)))))\n",
    "    r_S = i_Series.apply(lambda ks: list(set([input_dct[k] if k in input_dct.keys() else k for k in ks])))\n",
    "    print('keyword set size: {}'.format(len(set(itertools.chain.from_iterable(r_S)))))\n",
    "    return r_S\n",
    "\"\"\"\n",
    "Series를 Counter로 변환한 다음, below_weight보다 큰 node만 남기고 Series를 리턴\n",
    "\"\"\"\n",
    "def drop_lower_n(i_Series, below_weight=10):\n",
    "    print()\n",
    "    print(\"series에서 weight가 {}와 같거나 작은 node를 삭제합니다.\".format(below_weight))\n",
    "    print('keyword set size: {}'.format(len(set(itertools.chain.from_iterable(i_Series)))))\n",
    "    kwd_counter = {k:v for k, v in Counter(itertools.chain.from_iterable(i_Series)).most_common()}\n",
    "    r_S = i_Series.apply(lambda ks: list(set([k for k in ks if kwd_counter[k] >= below_weight])))\n",
    "    print('keyword set size: {}'.format(len(set(itertools.chain.from_iterable(r_S)))))\n",
    "    return r_S\n",
    "\"\"\"\n",
    "불필요한 remove_node를 삭제함\n",
    "\"\"\"\n",
    "def remove_node_from_series(i_Series, remove_nodes):\n",
    "    print(\"series에서 불필요한 node를 삭제합니다.\")\n",
    "    def func_remove_node(input_l):\n",
    "        return [k for k in input_l if k not in remove_nodes]\n",
    "    return i_Series.apply(func_remove_node)\n",
    "\"\"\"\n",
    "두 series로부터 bipartite graph를 만듬\n",
    "\"\"\"\n",
    "def make_bigraph_from_series(iS, jS):\n",
    "    if len(iS)!=len(jS):\n",
    "        print(\"different length of Series\")\n",
    "        return None\n",
    "    rG = nx.Graph()\n",
    "    edges = []\n",
    "    def make_edges_from_bipartite_sets(setA, setB):\n",
    "        if setA==[] or setB==[]:\n",
    "            return []\n",
    "        else:\n",
    "            return [(n1, n2+\"(i)\") for n1 in setA for n2 in setB]\n",
    "    for i in range(0, len(iS)):\n",
    "        edges+=make_edges_from_bipartite_sets(iS.iloc()[i], jS.iloc()[i])\n",
    "    rG.add_edges_from([(e[0][0], e[0][1], {'weight':e[1]}) for e in Counter(edges).most_common()])\n",
    "    print('is bipartite: {}'.format(nx.is_bipartite(rG)))\n",
    "    print('is connected: {}'.format(nx.is_connected(rG)))\n",
    "    return rG\n",
    "\n",
    "\n",
    "excel_path_and_filename = \"../../../Downloads/SMEs_Scopus_2013-2017.xlsx\"\n",
    "rawDF = pd.read_excel(excel_path_and_filename)\n",
    "df = rawDF[['Author Keywords', 'Year', 'Abstract', 'Index Keywords']].copy()\n",
    "\n",
    "author_series = basic_filter_Series(df['Author Keywords'])\n",
    "auth_syntactic_change_dict = syntactical_simialrity_dict(author_series, 10, 0.9)\n",
    "author_series = transform_by_dict(author_series, auth_syntactic_change_dict)\n",
    "author_series = drop_lower_n(author_series, 8)\n",
    "\n",
    "ind_series = basic_filter_Series(df['Index Keywords'])\n",
    "ind_syntactic_change_dict = syntactical_simialrity_dict(ind_series, 10, 0.9)\n",
    "ind_series = transform_by_dict(ind_series, ind_syntactic_change_dict)\n",
    "ind_series = drop_lower_n(ind_series, 15)\n",
    "\n",
    "\"\"\" adj matrix\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "remove node because it is useless\n",
    "이 부분은 clustering의 결과로 나온 cluster 중에서 분석하려고 하는 대상과 거리가 있는 키워드 묶음을 선정하여 기존 series에서 삭제하였다. \n",
    "\"\"\"\n",
    "author_series = remove_node_from_series(author_series, \n",
    "['shape memory', 'phase transformation', 'thermomechanical treatment', 'sma', 'stimuli sensitive polymers', 'actuator', 'shape memory polymer', 'superelasticity', 'martensitic transformation', 'microstructure', 'niti', 'nitinol', 'shape memory alloy', 'shape memory effect']\n",
    "+['fuzzy logic controller', 'power quality', 'energy management', 'battery', 'smart grid', 'energy storage', 'stability', 'photovoltaic', 'particle swarm optimization', 'power system', 'automatic generation control', 'transient stability', 'load frequency control', 'renewable energy', 'genetic algorithm', 'ac loss', 'high temperature superconductor', 'superconducting magnet', 'microgrid', 'power fluctuation', 'power']\n",
    "+['superconducting magnetic energy storage smes', 'optimization']\n",
    ")\n",
    "\n",
    "authG = make_graph_from_series(author_series)\n",
    "auth_adj_df = pd.DataFrame(\n",
    "    nx.adjacency_matrix(authG).toarray(), index=[n for n in authG.nodes()], columns=[n for n in authG.nodes()]\n",
    ")\n",
    "\n",
    "\"\"\"bipartite graph and bipartite adjacency matrix \n",
    "\"\"\"\n",
    "biG = make_bigraph_from_series(author_series, ind_series)\n",
    "row_order = nx.bipartite.sets(biG)[0]\n",
    "col_order = nx.bipartite.sets(biG)[1]\n",
    "bi_df = pd.DataFrame(\n",
    "    nx.bipartite.biadjacency_matrix(biG, row_order=row_order).toarray(),\n",
    "    index = row_order, columns = col_order\n",
    ")\n",
    "\n",
    "\"\"\" adj matrix\n",
    "\"\"\"\n",
    "\"\"\"clustering\n",
    "\"\"\"\n",
    "n_clusters = 20\n",
    "\n",
    "AGGmodel = cluster.AgglomerativeClustering(n_clusters=n_clusters)\n",
    "bi_cluster_df = pd.DataFrame(\n",
    "    # weight를 무시하고, 0, 1의 단일 연결로 하니까 더 잘되서 변환해서 거리를 잼\n",
    "    {'kwd': bi_df.index, 'cluster': AGGmodel.fit_predict(bi_df.apply(lambda col: [1 if x>=1 else 0 for x in col]))} \n",
    ")\n",
    "\n",
    "for i in range(0, n_clusters):\n",
    "    kwd_in_cluster = list(bi_cluster_df[bi_cluster_df['cluster']==i]['kwd'])\n",
    "    \"\"\"너무 많지도 적지도 않은 클러스터를 확인\n",
    "    \"\"\"\n",
    "    if len(kwd_in_cluster)>=2 and len(kwd_in_cluster)<50:\n",
    "        print(\"size of cluster {}: {}\".format(i, len(kwd_in_cluster)))\n",
    "        print(kwd_in_cluster)\n",
    "\n",
    "print(\"complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
