{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "train_url = 'https://storage.googleapis.com/kaggle-competitions-data/kaggle/3948/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1528789302&Signature=MkXhyDcwiyBvLhYLY%2FuOCt22uT7v8EJukp%2B2eaUOo8l2mheQIKxje34EPQwO77Y%2FR0O6NaGFcLIztLqMB1rlf0YbGTaVJ9W9di0F679WovNP32S3MKKc9DkR1RTwcqDiZUZgnHXUw9P4BasFk8hGvMfn0PBHSsPUJ%2F8sb98X5jeAks6oPxrNK8d98AfnF2f9S55aneuFavA1hIaU8d07Vqnv84RiFd3x7pJoOJYI%2BINwRfAJ0a0ksTx4UbxF%2BiQx7BPUIHf3sAFyK%2Bxtxg87K7bagU0Vw%2FpT08%2BXYzG4uZk%2B8EIY9zBu2dOac9aveFJ%2FkjlVjIXIdB2hNQyRjqRjwQ%3D%3D'\n",
    "test_url = 'https://storage.googleapis.com/kaggle-competitions-data/kaggle/3948/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1528789301&Signature=DhR8iDysdoMtVIevQ46p3JHt5bLLZNsl8DZsUUQtuBfW%2BG5%2FrMN5QWg3EkRKsX7zQidDFh0uHeRWCTQjwLld%2Fn2gek%2F%2BPuRTiwYAGWaBGhOhoxfdwTHvvlT0Ahb9XZaN2yRIOb1PGiWeAH6uaNrz6Ncg2y8tLafQrcpRI6Vi1qX2xusNSNZ%2BWfpS6mzOFJNLT1JBdQ3FL%2FSyzj10gSc0qmEZE%2FrL2aM5TCAsnvmYvXfz97hr6%2F4RSqqzTvSR4aoIiX6bTqj1EF01ni%2B9Ti7lzealQQzsHiv5G3vs%2FKGzEWSiJAd4B6snZ2sIOy0ghMm%2FVnq1RLms9frhq6flU8p%2B4A%3D%3D'\n",
    "\n",
    "train_df = pd.read_csv(train_url)\n",
    "test_df = pd.read_csv(test_url)\n",
    "\n",
    "#train_df = train_df[train_df['count'] < (count_mean + 3* count_std)].reset_index(drop=True)\n",
    "\n",
    "count_mean = train_df['count'].mean()\n",
    "count_std = train_df['count'].std()\n",
    "train_df = train_df[train_df['count'] < (count_mean + 3* count_std)]\n",
    "print(\"reading data complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----complete----\n"
     ]
    }
   ],
   "source": [
    "def rmsle(actual_values, predicted_values, convertExp=True):\n",
    "    \"\"\"\n",
    "    - root mean squared log error는 error를 로그화값으로 변환하고, 제곱하고, 평균을 내고, 루트를 씌웁니다.\n",
    "    - skewness를 해결하기 위해 np.log1p를 했기 때문에, 값을 예측할 때 이를 다시 변환해서 처리해주는 것이 필요합니다. \n",
    "    \"\"\"\n",
    "    if convertExp==True:\n",
    "        predicted_values = np.exp(predicted_values),\n",
    "        actual_values = np.exp(actual_values)\n",
    "        \n",
    "    log_predicted_values = np.log(np.array(predicted_values)+1)\n",
    "    log_actual_values = np.log(np.array(actual_values)+1)\n",
    "\n",
    "    # 위에서 계산한 예측값에서 실제값을 빼주고 제곱을 해준다.\n",
    "    difference = np.square(log_predicted_values - log_actual_values)\n",
    "    return np.sqrt(difference.mean())\n",
    "\n",
    "def preprocessingX(input_df):\n",
    "    r_df = input_df.copy()\n",
    "    r_df['datetime'] = pd.to_datetime(r_df['datetime'])\n",
    "    r_df['weekday'] = r_df['datetime'].apply(lambda d: d.weekday())\n",
    "    r_df['year'] = r_df['datetime'].apply(lambda dt: dt.year)\n",
    "    r_df['month'] = r_df['datetime'].apply(lambda dt: dt.month)\n",
    "    r_df['days'] = r_df['datetime'].apply(lambda dt: dt.day)\n",
    "    r_df['hour'] = r_df['datetime'].apply(lambda dt: dt.hour)\n",
    "    r_df['day_from_start'] = (r_df['datetime'] - r_df['datetime'][0]).apply(lambda td: td.days)\n",
    "    r_df['day_from_start//30'] = r_df['day_from_start']//30\n",
    "    r_df['day_from_start/180'] = r_df['day_from_start']//180\n",
    "    r_df['non_windspeed'] = r_df['windspeed'] ==0\n",
    "    try:\n",
    "        del r_df['registered']\n",
    "        del r_df['casual']\n",
    "    except:\n",
    "        pass\n",
    "    del r_df['datetime']\n",
    "    ## making categorical colm\n",
    "    for col in ['holiday', 'season', 'workingday', 'hour']:\n",
    "        r_df = r_df.join(pd.get_dummies(r_df[col], prefix=col)) \n",
    "    r_df_v = r_df.values\n",
    "    #r_df_v = RobustScaler().fit_transform(r_df_v)\n",
    "    ##r_df_v = MinMaxScaler().fit_transform(r_df_v)\n",
    "    return pd.DataFrame(r_df_v, columns=r_df.columns)\n",
    "\n",
    "# outlier removal \n",
    "\n",
    "x = preprocessingX(train_df[list(set(train_df.columns)-set(['count']))])\n",
    "y = train_df['count']\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x.values, y_log, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "#reg = GradientBoostingRegressor(n_estimators=5000, alpha=0.01)\n",
    "#reg = MLPRegressor(hidden_layer_sizes=[512, 64, 4], max_iter=1000, alpha=0.005, random_state=42)\n",
    "\n",
    "#reg = GridSearchCV(  Lasso(), { 'max_iter':[3000], 'alpha':1/np.array([0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000])}, cv=5)\n",
    "#reg = GridSearchCV(GradientBoostingRegressor(), {\"n_estimators\":[5, 500, 1000], 'alpha':[0.001, 0.01, 0.1, 0.5]}, scoring=make_scorer(rmsle))\n",
    "\n",
    "reg = GridSearchCV(GradientBoostingRegressor(), {\"n_estimators\":[4000], 'alpha':[0.01]}, cv=3,\n",
    "                   scoring=make_scorer(rmsle))\n",
    "reg = GridSearchCV(RandomForestRegressor(), {\"n_estimators\":[5, 50, 100, 500]}, cv=3,\n",
    "                   scoring=make_scorer(rmsle))\n",
    "reg.fit(x.values, y_log)\n",
    "\n",
    "## submission \n",
    "submit_df = pd.DataFrame({'datetime':test_df['datetime'], \n",
    "                          'count':[max(0, x) for x in np.exp(reg.predict(preprocessingX(test_df)))],\n",
    "                          #'count':list(map(lambda x: round(x, 0), np.exp(reg.predict(preprocessingX(test_df)))))\n",
    "                         })\n",
    "submit_df.to_csv('bycicle.csv', index=False)\n",
    "print(\"----complete----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# root mean squared logarithmic error라는데, 이걸 계산하는 식을 만들어서 비교를 해보는 게 좋을듯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
