{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "\"\"\"\n",
    "- layer instance들은 모두 callable object, \n",
    "- tensor를 입력받아서 tensor를 리턴함.\n",
    "- 특히, Sequential에서는 맨처음 레이어에서만 input_dims만 설정해주고, \n",
    "- 쭉 선형적으로 리스트처럼 나열해줬는데, \n",
    "- model에서는 매 레이어마다 어디서 input을 받는지, argument의 형태로 모두 정의해주어야 함.\n",
    "\"\"\"\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "D1 = Dense(64, activation='relu')(inputs) \n",
    "D2 = Dense(64, activation='relu')(D1)\n",
    "predictions = Dense(10, activation='softmax')(D2)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#model.fit(data, labels)  # starts training\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b264ac7a4933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(784,))\n",
    "\n",
    "y = model(x)\n",
    "y.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential \n",
    "\n",
    "\"\"\"\n",
    "- Sequential 로는 다음처럼 표현할 수 있다. \n",
    "- 맨 처음에, InputLayer만 없는것을 제외하면 나머지는 동일함. \n",
    "\"\"\"\n",
    "seq_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(784,)), \n",
    "    Dense(64, activation='relu'), \n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "seq_model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.fit(data, labels)  # starts training\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "#### Sequential Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 472,042\n",
      "Trainable params: 472,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5s - loss: 0.4286 - categorical_accuracy: 0.8777\n",
      "Epoch 2/5\n",
      "5s - loss: 0.1444 - categorical_accuracy: 0.9593\n",
      "Epoch 3/5\n",
      "5s - loss: 0.0938 - categorical_accuracy: 0.9734\n",
      "Epoch 4/5\n",
      "5s - loss: 0.0673 - categorical_accuracy: 0.9803\n",
      "Epoch 5/5\n",
      "5s - loss: 0.0507 - categorical_accuracy: 0.9844\n",
      "train, loss and metric: [0.038528761140324851, 0.98901818185286083]\n",
      "test, loss and metric: [0.083338848683051761, 0.97560000000000002]\n"
     ]
    }
   ],
   "source": [
    "#### data reading\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "x_train, y_train = mnist.train.images, mnist.train.labels\n",
    "x_test, y_test = mnist.test.images, mnist.test.labels\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import metrics\n",
    "\n",
    "## sequential model \n",
    "seq_model = Sequential([\n",
    "    Dense(512, input_shape=(784,), activation='relu'), \n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "print(\"#### Sequential Model\")\n",
    "seq_model.summary()\n",
    "seq_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8),\n",
    "              metrics=[metrics.categorical_accuracy])\n",
    "train_history = seq_model.fit(x_train, y_train, epochs=5, batch_size=500, verbose=2)\n",
    "train_history = train_history.history # epoch마다 변화한 loss, metric\n",
    "\n",
    "loss_and_metric = seq_model.evaluate(x_train, y_train, batch_size=128, verbose=0)\n",
    "print(\"train, loss and metric: {}\".format(loss_and_metric))\n",
    "loss_and_metric = seq_model.evaluate(x_test, y_test, batch_size=128, verbose=0)\n",
    "print(\"test, loss and metric: {}\".format(loss_and_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 472,042\n",
      "Trainable params: 472,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "train, loss and metric: [0.041054270681467921, 0.98849090910824866]\n",
      "train, loss and metric: [0.078584650909528139, 0.97660000000000002]\n"
     ]
    }
   ],
   "source": [
    "input2 = Input(shape=(784,))\n",
    "nD1 = seq_model.layers[0](input2)\n",
    "nD2 = seq_model.layers[1](nD1)\n",
    "nD3 = seq_model.layers[2](nD2)\n",
    "nD4 = seq_model.layers[3](nD3) #nD4 = model.layers[4](nD3)\n",
    "model1 = Model(input2, nD4)\n",
    "model1.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8),\n",
    "              metrics=[metrics.categorical_accuracy])\n",
    "model1.summary()\n",
    "\n",
    "loss_and_metric = model1.evaluate(x_train, y_train, batch_size=128, verbose=0)\n",
    "print(\"train, loss and metric: {}\".format(loss_and_metric))\n",
    "loss_and_metric = model1.evaluate(x_test, y_test, batch_size=128, verbose=0)\n",
    "print(\"train, loss and metric: {}\".format(loss_and_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, loss and metric: [0.041054270681467921, 0.98849090910824866]\n",
      "train, loss and metric: [0.078584650909528139, 0.97660000000000002]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metric = model1.evaluate(x_train, y_train, batch_size=128, verbose=0)\n",
    "print(\"train, loss and metric: {}\".format(loss_and_metric))\n",
    "loss_and_metric = model1.evaluate(x_test, y_test, batch_size=128, verbose=0)\n",
    "print(\"train, loss and metric: {}\".format(loss_and_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# Input tensor for sequences of 20 timesteps,\n",
    "# each containing a 784-dimensional vector\n",
    "input_sequences = Input(shape=(20, 784))\n",
    "# This applies our previous model to every timestep in the input sequences.\n",
    "# the output of the previous model was a 10-way softmax,\n",
    "# so the output of the layer below will be a sequence of 20 vectors of size 10.\n",
    "processed_sequences = TimeDistributed(seq_model)(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 472,042\n",
      "Trainable params: 472,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "#######################\n",
    "#### concatenate inputs\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
