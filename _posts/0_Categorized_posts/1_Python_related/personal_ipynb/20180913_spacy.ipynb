{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 공사파이 발표 정리 \n",
    "\n",
    "- spacy \n",
    "- POS tagging: 품사 만들기 \n",
    "- \n",
    "- NER(named entity recognition): 지명 인명 회사명 등 인식\n",
    "- noun chunking: 명사구 묶기\n",
    "\n",
    "- textacy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pos tagging\n",
    "\n",
    "import spacy \n",
    "\n",
    "## https://spacy.io/models/en\n",
    "## 자연어처리를 위해 어떤 통계적인 모델을 사용할지를 결정합니다. \n",
    "## sm, md, lg 로 나뉘며, 당연히 lg가 제일 좋기는 하지만, 퍼센트상으로는 1퍼센트 내외정도 차이가 나므로 큰 문제가 없다고 보여집니다. \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The original word text.\n",
      "Lemma: The base form of the word.(축약한 상태)\n",
      "POS: The simple part-of-speech tag.\n",
      "Tag: The detailed part-of-speech tag.\n",
      "Dep: Syntactic dependency, i.e. the relation between tokens.\n",
      "Shape: The word shape – capitalisation, punctuation, digits.\n",
      "is alpha: Is the token an alpha character?\n",
      "is stop: Is the token part of a stop list, i.e. the most common words of the language?\n",
      "================================================================================\n",
      "      Text     Lemma       POS       Tag       Dep     Shape  is alpha   is stop\n",
      "================================================================================\n",
      "     Apple     apple     PROPN       NNP     nsubj     Xxxxx         1         0\n",
      "        is        be      VERB       VBZ       aux        xx         1         1\n",
      "   looking      look      VERB       VBG      ROOT      xxxx         1         0\n",
      "        at        at       ADP        IN      prep        xx         1         1\n",
      "    buying       buy      VERB       VBG     pcomp      xxxx         1         0\n",
      "      U.K.      u.k.     PROPN       NNP  compound      X.X.         0         0\n",
      "   startup   startup      NOUN        NN      dobj      xxxx         1         0\n",
      "       for       for       ADP        IN      prep       xxx         1         1\n",
      "         $         $       SYM         $  quantmod         $         0         0\n",
      "         1         1       NUM        CD  compound         d         0         0\n",
      "   billion   billion       NUM        CD      pobj      xxxx         1         0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "Apple is looking at buyin at U.K startup for $1 billion.\n",
      "[Apple, is, looking, at, buyin, at, U.K, startup, for, $, 1, billion, .]\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy \n",
    "## 다음처럼 spacy에서 내가 원하는 언어의 모델을 가져오고, \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "## 다음처럼 문장을 nlp에 넘기기만 하면 끝납니다. \n",
    "doc = nlp('Apple is looking at buyin at U.K startup for $1 billion.')\n",
    "print(type(doc)) ## 타입은, Doc고, \n",
    "print(doc)## 그냥 출력하면, 원래 문장이 그대로 나오고, \n",
    "print(list(doc))## 리스트로 변형하면, tokenize한 결과가 나오고 \n",
    "print(type(doc[0]))## 리스트의 가장 앞에 있는 값은 Token이라는 타입이죠. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The original word text.\n",
      "Lemma: The base form of the word.(축약한 상태)\n",
      "POS: The simple part-of-speech tag.\n",
      "Tag: The detailed part-of-speech tag.\n",
      "Dep: Syntactic dependency, i.e. the relation between tokens.\n",
      "Shape: The word shape – capitalisation, punctuation, digits.\n",
      "is alpha: Is the token an alpha character?\n",
      "is stop: Is the token part of a stop list, i.e. the most common words of the language?\n",
      "================================================================================\n",
      "      Text     Lemma       POS       Tag       Dep     Shape  is alpha   is stop\n",
      "================================================================================\n",
      "     Apple     apple     PROPN       NNP     nsubj     Xxxxx      True     False\n",
      "        is        be      VERB       VBZ       aux        xx      True      True\n",
      "   looking      look      VERB       VBG      ROOT      xxxx      True     False\n",
      "        at        at       ADP        IN      prep        xx      True      True\n",
      "    buying       buy      VERB       VBG     pcomp      xxxx      True     False\n",
      "      U.K.      u.k.     PROPN       NNP  compound      X.X.     False     False\n",
      "   startup   startup      NOUN        NN      dobj      xxxx      True     False\n",
      "       for       for       ADP        IN      prep       xxx      True      True\n",
      "         $         $       SYM         $  quantmod         $     False     False\n",
      "         1         1       NUM        CD  compound         d     False     False\n",
      "   billion   billion       NUM        CD      pobj      xxxx      True     False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## part of speech tagging \n",
    "\n",
    "temp_str = \"\"\"\n",
    "Text: The original word text.\n",
    "Lemma: The base form of the word.(축약한 상태)\n",
    "POS: The simple part-of-speech tag.\n",
    "Tag: The detailed part-of-speech tag.\n",
    "Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "Shape: The word shape – capitalisation, punctuation, digits.\n",
    "is alpha: Is the token an alpha character?\n",
    "is stop: Is the token part of a stop list, i.e. the most common words of the language?\n",
    "\"\"\".strip()\n",
    "print(temp_str)\n",
    "print(\"==\"*40)\n",
    "\n",
    "str_format = \"{:>10}\"*8\n",
    "print(str_format.format(*temp_dict.keys()))\n",
    "print(\"==\"*40)\n",
    "\n",
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "for token in doc:\n",
    "    print(str_format.format(token.text, token.lemma_, token.pos_, token.tag_, \n",
    "                            token.dep_, token.shape_, str(token.is_alpha), str(token.is_stop)))\n",
    "    \n",
    "#displacy.render(doc, style='dep', jupyter=True)\n",
    "str(token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple looking\n",
      "U.K. startup buying\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "for noun_c in doc.noun_chunks:\n",
    "    print(noun_c, noun_c.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "============================================================\n",
      "Text: The original noun chunk text.\n",
      "Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n",
      "Root dep: Dependency relation connecting the root to its head.\n",
      "Root head text: The text of the root token's head.\n",
      "============================================================\n",
      "          Autonomous cars                     cars                    nsubj                    shift\n",
      "      insurance liability                liability                     dobj                    shift\n",
      "            manufacturers            manufacturers                     pobj                   toward\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "\n",
    "## 특정 텍스트를 nlp에 넘기면 모두 해결되기는 하는데, \n",
    "## noun_chunks의 경우는 token 클래스도 아니고, Doc 클래스도 아니다. \n",
    "## Span이라는 클래스는 그냥 Doc와 비슷하다고 생각하면 된다, 일종의 복합어 개념.\n",
    "noun_chunks = doc.noun_chunks\n",
    "print(type(noun_chunks))\n",
    "noun_chunk = list(noun_chunks)[0]\n",
    "print(type(noun_chunk))\n",
    "token = noun_chunk[0]\n",
    "print(type(token))\n",
    "\n",
    "print(\"==\"*30)\n",
    "print(\"\"\"\n",
    "Text: The original noun chunk text.\n",
    "Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n",
    "Root dep: Dependency relation connecting the root to its head.\n",
    "Root head text: The text of the root token's head.\n",
    "\"\"\".strip())\n",
    "print(\"==\"*30)\n",
    "str_format = \"{:>25}\"*4\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(str_format.format(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "a = list(doc.noun_chunks)[0]\n",
    "print(type(a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous\n",
      "children: [] head: cars\n",
      "================================\n",
      "cars\n",
      "children: [Autonomous] head: shift\n",
      "================================\n",
      "shift\n",
      "children: [cars, liability, toward] head: !this is root node\n",
      "================================\n",
      "insurance\n",
      "children: [] head: liability\n",
      "================================\n",
      "liability\n",
      "children: [insurance] head: shift\n",
      "================================\n",
      "toward\n",
      "children: [manufacturers] head: shift\n",
      "================================\n",
      "manufacturers\n",
      "children: [] head: toward\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "## navigina parse tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for tok in doc:\n",
    "    print(tok.text)\n",
    "    children = list(tok.children)\n",
    "    print('children:', children, 'head:', tok.head if tok.head != tok else \"!this is root node\")\n",
    "    print(\"==\"*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(shift, {}), (cars, {}), (liability, {}), (toward, {}), (Autonomous, {}), (insurance, {}), (manufacturers, {})]\n",
      "========================================\n",
      "shift, cars, ### dependency: nsubj\n",
      "shift, liability, ### dependency: dobj\n",
      "shift, toward, ### dependency: prep\n",
      "cars, Autonomous, ### dependency: amod\n",
      "liability, insurance, ### dependency: compound\n",
      "toward, manufacturers, ### dependency: pobj\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "nG = nx.Graph()\n",
    "doc[2] ## root node\n",
    "\n",
    "def add_n_to_g(inputG, tok):\n",
    "    inputG.add_node(tok)\n",
    "    children = list(tok.children)\n",
    "    if children != []:\n",
    "        inputG.add_nodes_from(children)\n",
    "        for c in children:\n",
    "            inputG.add_edges_from([(tok, c, {'dependency':c.dep_})])\n",
    "            add_n_to_g(inputG, c)\n",
    "add_n_to_g(nG, doc[2])\n",
    "print(nG.nodes(data=True))\n",
    "print(\"==\"*20)\n",
    "for e in nG.edges(data=True):\n",
    "    print(f\"{e[0]}, {e[1]}, ### dependency: {e[2]['dependency']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google ORG\n",
      "Apple ORG\n",
      "iPhones PRODUCT\n",
      "Amazon ORG\n",
      "Alexa ORG\n",
      "Echo GPE\n",
      "Dot ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"But Google is starting from behind. The company made a late push\n",
    "into hardware, and Apple’s Siri, available on iPhones, and Amazon’s Alexa\n",
    "software, which runs on its Echo and Dot devices, have clear leads in\n",
    "consumer adoption.\"\"\".replace(\"\\n\", \" \").strip())\n",
    "\n",
    "## 아래처럼 무엇이 organization이고, 무엇이 product인지, 꽤 잘 구별해주지만, \n",
    "## echo, dot 등에 대해서는 정확하지 못하다. \n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True False\n",
      "cat True False\n",
      "banana True False\n",
      "apple True False\n",
      "afskfsd False True\n",
      "==============================\n",
      "dog dog 1.0\n",
      "dog cat 2.30727e-21\n",
      "dog banana -7.82874e+17\n",
      "dog apple -2.1605e-21\n",
      "cat dog 2.30727e-21\n",
      "cat cat 1.0\n",
      "cat banana -8.24222e+17\n",
      "cat apple -2.2746e-21\n",
      "banana dog 0.0\n",
      "banana cat -0.0446812\n",
      "banana banana 1.0\n",
      "banana apple -7.7179e+17\n",
      "apple dog 0.0\n",
      "apple cat -0.041959\n",
      "apple banana -7.7179e+17\n",
      "apple apple 1.0\n"
     ]
    }
   ],
   "source": [
    "## word similarity\n",
    "\n",
    "import pandas as pd\n",
    "#nlp = spacy.load('en_core_web_md')  # make sure to use larger model!\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "tokens = nlp('dog cat banana apple afskfsd')\n",
    "\n",
    "for token in tokens:\n",
    "    #token.vector 벡터 자체는 왼쪽 명령어를 사용 \n",
    "    ## is_oov means out-of-vocab\n",
    "    print(token.text, token.has_vector, token.is_oov)\n",
    "print(\"===\"*10)\n",
    "## vocab에 포함되지 않은 경우는 제외함. \n",
    "tokens = filter(lambda x: not x.is_oov, tokens)\n",
    "tokens = list(tokens)\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1, token2, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog cat 0.0\n",
      "dog banana 0.0\n",
      "cat dog 0.0\n",
      "cat cat 1.0\n",
      "cat banana -0.0446812\n",
      "banana dog -7.82874e+17\n",
      "banana cat -8.24222e+17\n",
      "banana banana 1.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_md\n",
    "\n",
    "nlp = en_core_web_md.load()\n",
    "#nlp = spacy.load('en_core_web_lg')  # make sure to use larger model!\n",
    "tokens = nlp(u'dog cat banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-308-64c704957853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moranges_apples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moranges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0moranges_apples\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mapples_oranges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "#nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "apples, _, oranges = nlp('apples and oranges')\n",
    "apples_oranges = apples.similarity(oranges)\n",
    "oranges_apples = oranges.similarity(apples)\n",
    "\n",
    "assert oranges_apples==apples_oranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog [[ -3.68934881e+19]]\n",
      "dog cat [[ 2.]]\n",
      "dog banana [[ 2.]]\n",
      "cat dog [[ 2.]]\n",
      "cat cat [[ -3.68934881e+19]]\n",
      "cat banana [[ -1.08420217e-19]]\n",
      "banana dog [[ 2.]]\n",
      "banana cat [[ -1.08420217e-19]]\n",
      "banana banana [[  1.08420217e-19]]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')  # make sure to use larger model!\n",
    "tokens = nlp(u'dog cat banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        ## np.dot(token1.vector, token2.vector) / (token1.vector_norm*token2.vector_norm)\n",
    "        sim = cosine_similarity(token1.vector.reshape(1, 300), \n",
    "                          token2.vector.reshape(1, 300)\n",
    "                         )\n",
    "        print(token1.text, token2.text, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        ## np.dot(token1.vector, token2.vector) / (token1.vector_norm*token2.vector_norm)\n",
    "        cosine_similarity(token1.vector.reshape(1, 300), \n",
    "                          token2.vector.reshape(1, 300)\n",
    "                         )\n",
    "        print(token1.text, token2.text, token1.similarity(token2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.30001"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apples.vector[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dog,    dog: [[ -3.68934881e+19]]\n",
      "-2.19152e-21\n",
      "   dog,    cat: [[ 2.]]\n",
      "2.30727e-21\n",
      "   dog, banana: [[ 2.]]\n",
      "-7.82874e+17\n",
      "   cat,    dog: [[ 2.]]\n",
      "2.30727e-21\n",
      "   cat,    cat: [[ -3.68934881e+19]]\n",
      "0.0448096\n",
      "   cat, banana: [[ -1.08420217e-19]]\n",
      "-8.24222e+17\n",
      "banana,    dog: [[ 2.]]\n",
      "0.0\n",
      "banana,    cat: [[ -1.08420217e-19]]\n",
      "-0.0446812\n",
      "banana, banana: [[  1.08420217e-19]]\n",
      "-0.0445532\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp('dog cat banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        sim = cosine_similarity(token1.vector.reshape(1, 300), \n",
    "                                  token2.vector.reshape(1, 300)\n",
    "                                 )\n",
    "        print(\"{:>6s}, {:>6s}: {}\".format(token1.text, token2.text, sim))\n",
    "        print(np.dot(token1.vector, token2.vector) / (token1.vector_norm*token2.vector_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"2150\" height=\"487.0\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">U.K</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">million</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,177.0 390.0,177.0 390.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,354.0 L748.0,342.0 732.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M770,352.0 C770,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,354.0 L1278.0,342.0 1262.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M770,352.0 C770,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,177.0 1965.0,177.0 1965.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-10\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,89.5 1970.0,89.5 1970.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-10\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1970.0,354.0 L1978.0,342.0 1962.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp('Apple is looking a buying a U.K startup for $1 million')\n",
    "## https://stackoverflow.com/questions/49750376/visualise-dependency-parse-using-displacy-python\n",
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n",
      "====================\n",
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.sentiment\n",
    "doc1 = nlp(\"I am happy\")\n",
    "\n",
    "doc1.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "U.K.\n",
      "$1 billion\n",
      "====================\n",
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text)\n",
    "print(\"=\"*20)\n",
    "for tok in doc:\n",
    "    print(tok.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Empirical evidence for links between human capital and entrepreneurship potential is equivocal despite a wide range of studies. This research draws on prospective longitudinal data from the National Child Development Study (NCDS) to offer new theoretical perspectives and empirical evidence on the human capital predictors that drive entrepreneurship. The results suggest that start-up is more likely for those who demonstrate higher levels of analytical and creative abilities in childhood, benefit from a supportive family background, invest in their human capital through diverse and longer work experience and have accrued a solid basic education, albeit not strongly credentialed. This article contributes to a better understanding of human capital acquisition during the unfolding entrepreneurial life-course. Mediators and moderators of the relationship between education, human capital and entrepreneurship are also identified by accentuating the importance of family processes. In doing so, this study bridges the human capital and cultural capital literatures that have tended to evolve on separate tracks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_text = \"\"\"\n",
    "Empirical evidence for links between human capital and entrepreneurship potential is equivocal despite a wide range of studies. This research draws on prospective longitudinal data from the National Child Development Study (NCDS) to offer new theoretical perspectives and empirical evidence on the human capital predictors that drive entrepreneurship. The results suggest that start-up is more likely for those who demonstrate higher levels of analytical and creative abilities in childhood, benefit from a supportive family background, invest in their human capital through diverse and longer work experience and have accrued a solid basic education, albeit not strongly credentialed. This article contributes to a better understanding of human capital acquisition during the unfolding entrepreneurial life-course. Mediators and moderators of the relationship between education, human capital and entrepreneurship are also identified by accentuating the importance of family processes. In doing so, this study bridges the human capital and cultural capital literatures that have tended to evolve on separate tracks.\n",
    "\"\"\"\n",
    "print(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is looking a buying a U.K startup for $1 million\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    print(\"====\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['empirical evidence', 'link', 'human capital', 'entrepreneurship', 'potential', 'a wide range', 'study']\n",
      "====================\n",
      "['this research', 'prospective longitudinal datum', 'the national child development study', 'ncds', 'new theoretical perspective', 'empirical evidence', 'the human capital predictor', 'entrepreneurship']\n",
      "====================\n",
      "['the result', 'start up', 'who', 'high level', 'analytical and creative ability', 'childhood', 'a supportive family background', ' PRON human capital', 'diverse and long work experience', 'a solid basic education']\n",
      "====================\n",
      "['this article', 'a good understanding', 'human capital acquisition', 'the unfold entrepreneurial life course']\n",
      "====================\n",
      "['mediator', 'moderator', 'the relationship', 'education', 'human capital', 'entrepreneurship', 'the importance', 'family process']\n",
      "====================\n",
      "['this study', 'the human capital and cultural capital literature', 'separate track']\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "## 문장 뽑기 \n",
    "doc = nlp(target_text.strip())\n",
    "for sent in doc.sents:\n",
    "    noun_chunks = [n.lemma_ for n in sent.noun_chunks]\n",
    "    noun_chunks = [n.replace(\"-\", \" \") for n in noun_chunks]\n",
    "    new_noun_chunks = []\n",
    "    for n in noun_chunks:\n",
    "        while \"  \" in n:\n",
    "            n = n.replace(\"  \", \" \")\n",
    "        new_noun_chunks.append(n)\n",
    "    print(new_noun_chunks)\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " Empirical evidence for links between human capital and entrepreneurship,\n",
       " potential is equivocal despite a wide range of studies.,\n",
       " This research draws on prospective longitudinal data from the National Child Development Study (NCDS) to offer new theoretical perspectives and empirical evidence on the human capital predictors that drive entrepreneurship.,\n",
       " The results suggest that start-up is more likely for those who demonstrate higher levels of analytical and creative abilities in childhood, benefit from a supportive family background, invest in their human capital through diverse and longer work experience and have accrued a solid basic education, albeit not strongly credentialed.,\n",
       " This article contributes to a better understanding of human capital acquisition during the unfolding entrepreneurial life-course.,\n",
       " Mediators and moderators of the relationship between education, human capital and entrepreneurship are also identified by accentuating the importance of family processes.,\n",
       " In doing so, this study bridges the human capital and cultural capital literatures that have tended to evolve on separate tracks.]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(target_text)\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Empirical evidence for links between human capital and entrepreneurship\n",
      "\n",
      "  SPACE\n",
      "Empirical ROOT ADJ\n",
      "evidence dobj NOUN\n",
      "for prep ADP\n",
      "links pobj NOUN\n",
      "between prep ADP\n",
      "human amod ADJ\n",
      "capital pobj NOUN\n",
      "and cc CCONJ\n",
      "entrepreneurship conj NOUN\n",
      "====================\n",
      "potential is equivocal despite a wide range of studies.\n",
      "potential nsubj NOUN\n",
      "is ROOT VERB\n",
      "equivocal acomp ADJ\n",
      "despite prep ADP\n",
      "a det DET\n",
      "wide amod ADJ\n",
      "range pobj NOUN\n",
      "of prep ADP\n",
      "studies pobj NOUN\n",
      ". punct PUNCT\n",
      "====================\n",
      "This research draws on prospective longitudinal data from the National Child Development Study (NCDS) to offer new theoretical perspectives and empirical evidence on the human capital predictors that drive entrepreneurship.\n",
      "This det DET\n",
      "research nsubj NOUN\n",
      "draws ROOT VERB\n",
      "on prep ADP\n",
      "prospective amod ADJ\n",
      "longitudinal amod ADJ\n",
      "data pobj NOUN\n",
      "from prep ADP\n",
      "the det DET\n",
      "National compound PROPN\n",
      "Child compound PROPN\n",
      "Development compound PROPN\n",
      "Study pobj PROPN\n",
      "( punct PUNCT\n",
      "NCDS appos PROPN\n",
      ") punct PUNCT\n",
      "to aux PART\n",
      "offer advcl VERB\n",
      "new amod ADJ\n",
      "theoretical amod ADJ\n",
      "perspectives dobj NOUN\n",
      "and cc CCONJ\n",
      "empirical amod ADJ\n",
      "evidence conj NOUN\n",
      "on prep ADP\n",
      "the det DET\n",
      "human amod ADJ\n",
      "capital compound NOUN\n",
      "predictors pobj NOUN\n",
      "that nsubj ADJ\n",
      "drive relcl VERB\n",
      "entrepreneurship dobj NOUN\n",
      ". punct PUNCT\n",
      "====================\n",
      "The results suggest that start-up is more likely for those who demonstrate higher levels of analytical and creative abilities in childhood, benefit from a supportive family background, invest in their human capital through diverse and longer work experience and have accrued a solid basic education, albeit not strongly credentialed.\n",
      "The det DET\n",
      "results nsubj NOUN\n",
      "suggest ROOT VERB\n",
      "that mark ADP\n",
      "start compound NOUN\n",
      "- punct PUNCT\n",
      "up nsubj NOUN\n",
      "is ccomp VERB\n",
      "more advmod ADV\n",
      "likely acomp ADJ\n",
      "for prep ADP\n",
      "those pobj DET\n",
      "who nsubj NOUN\n",
      "demonstrate relcl VERB\n",
      "higher amod ADJ\n",
      "levels dobj NOUN\n",
      "of prep ADP\n",
      "analytical amod ADJ\n",
      "and cc CCONJ\n",
      "creative conj ADJ\n",
      "abilities pobj NOUN\n",
      "in prep ADP\n",
      "childhood pobj NOUN\n",
      ", punct PUNCT\n",
      "benefit conj VERB\n",
      "from prep ADP\n",
      "a det DET\n",
      "supportive amod ADJ\n",
      "family compound NOUN\n",
      "background pobj NOUN\n",
      ", punct PUNCT\n",
      "invest conj VERB\n",
      "in prep ADP\n",
      "their poss ADJ\n",
      "human amod ADJ\n",
      "capital pobj NOUN\n",
      "through prep ADP\n",
      "diverse amod ADJ\n",
      "and cc CCONJ\n",
      "longer advmod ADJ\n",
      "work conj NOUN\n",
      "experience pobj NOUN\n",
      "and cc CCONJ\n",
      "have aux VERB\n",
      "accrued conj VERB\n",
      "a det DET\n",
      "solid amod ADJ\n",
      "basic amod ADJ\n",
      "education dobj NOUN\n",
      ", punct PUNCT\n",
      "albeit advmod ADP\n",
      "not neg ADV\n",
      "strongly advmod ADV\n",
      "credentialed conj VERB\n",
      ". punct PUNCT\n",
      "====================\n",
      "This article contributes to a better understanding of human capital acquisition during the unfolding entrepreneurial life-course.\n",
      "This det DET\n",
      "article nsubj NOUN\n",
      "contributes ROOT VERB\n",
      "to prep ADP\n",
      "a det DET\n",
      "better amod ADJ\n",
      "understanding pobj NOUN\n",
      "of prep ADP\n",
      "human amod ADJ\n",
      "capital compound NOUN\n",
      "acquisition pobj NOUN\n",
      "during prep ADP\n",
      "the det DET\n",
      "unfolding amod VERB\n",
      "entrepreneurial amod ADJ\n",
      "life compound NOUN\n",
      "- punct PUNCT\n",
      "course pobj NOUN\n",
      ". punct PUNCT\n",
      "====================\n",
      "Mediators and moderators of the relationship between education, human capital and entrepreneurship are also identified by accentuating the importance of family processes.\n",
      "Mediators nsubjpass NOUN\n",
      "and cc CCONJ\n",
      "moderators conj NOUN\n",
      "of prep ADP\n",
      "the det DET\n",
      "relationship pobj NOUN\n",
      "between prep ADP\n",
      "education pobj NOUN\n",
      ", punct PUNCT\n",
      "human amod ADJ\n",
      "capital conj NOUN\n",
      "and cc CCONJ\n",
      "entrepreneurship conj NOUN\n",
      "are auxpass VERB\n",
      "also advmod ADV\n",
      "identified ROOT VERB\n",
      "by prep ADP\n",
      "accentuating pcomp VERB\n",
      "the det DET\n",
      "importance dobj NOUN\n",
      "of prep ADP\n",
      "family compound NOUN\n",
      "processes pobj NOUN\n",
      ". punct PUNCT\n",
      "====================\n",
      "In doing so, this study bridges the human capital and cultural capital literatures that have tended to evolve on separate tracks.\n",
      "\n",
      "In prep ADP\n",
      "doing pcomp VERB\n",
      "so advmod ADV\n",
      ", punct PUNCT\n",
      "this det DET\n",
      "study nsubj NOUN\n",
      "bridges ROOT VERB\n",
      "the det DET\n",
      "human amod ADJ\n",
      "capital nmod NOUN\n",
      "and cc CCONJ\n",
      "cultural conj ADJ\n",
      "capital compound NOUN\n",
      "literatures dobj NOUN\n",
      "that nsubj ADJ\n",
      "have aux VERB\n",
      "tended relcl VERB\n",
      "to aux PART\n",
      "evolve xcomp VERB\n",
      "on prep ADP\n",
      "separate amod ADJ\n",
      "tracks pobj NOUN\n",
      ". punct PUNCT\n",
      "\n",
      "  SPACE\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "## 문장 뽑기 \n",
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    for n in sent:\n",
    "        print(n, n.dep_, n.pos_)\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Empirical evidence,\n",
       " links,\n",
       " human capital,\n",
       " entrepreneurship,\n",
       " potential,\n",
       " a wide range,\n",
       " studies]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 명사구만 뽑아내기 \n",
    "doc = nlp(target_sent)\n",
    "list(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4335151158952394e-21"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## similarity between abstract\n",
    "\n",
    "abs1 = 'Empirical evidence for links between human capital and entrepreneurship potential is equivocal despite a wide range of studies. This research draws on prospective longitudinal data from the National Child Development Study (NCDS) to offer new theoretical perspectives and empirical evidence on the human capital predictors that drive entrepreneurship. The results suggest that start-up is more likely for those who demonstrate higher levels of analytical and creative abilities in childhood, benefit from a supportive family background, invest in their human capital through diverse and longer work experience and have accrued a solid basic education, albeit not strongly credentialed. This article contributes to a better understanding of human capital acquisition during the unfolding entrepreneurial life-course. Mediators and moderators of the relationship between education, human capital and entrepreneurship are also identified by accentuating the importance of family processes. In doing so, this study bridges the human capital and cultural capital literatures that have tended to evolve on separate tracks.'\n",
    "abs2 = 'This article examines the role played by small states in the promotion or reinforcement of new ideas and emerging norms within international society. More specifically, it examines the role played by Norway in reinforcing the normative framework of ‘women, peace and security’, with a particular view to Norway’s first period of membership in the United Nations Peacebuilding Commission. Norway is regarded internationally as one of the lead countries in terms of promoting women’s rights in relation to peace and security. The article discusses four possible reasons that may explain Norway’s apparent suitability and effectiveness as a norm entrepreneur in this particular issue-area.'\n",
    "doc1 = nlp(abs1)\n",
    "doc2 = nlp(abs2)\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## document에 대해서도, document vector를 보여줌 \n",
    "w1 = nlp(\"female entrepreneur\")\n",
    "w2 = nlp(\"woman entrepreneur\")\n",
    "w1.similarity(w2)\n",
    "#doc1.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_similarity(text1, text2):\n",
    "    return nlp(text1).similarity(nlp(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical evidence for links between human capital and entrepreneurship potential is equivocal despite a wide range of studies.\n",
      "[Empirical evidence, links, human capital, entrepreneurship, potential, a wide range, studies]\n",
      "==================================================\n",
      "This research draws on prospective longitudinal data from the National Child Development Study (NCDS) to offer new theoretical perspectives and empirical evidence on the human capital predictors that drive entrepreneurship.\n",
      "[This research, prospective longitudinal data, the National Child Development Study, NCDS, new theoretical perspectives, empirical evidence, the human capital predictors, entrepreneurship]\n",
      "==================================================\n",
      "The results suggest that start-up is more likely for those who demonstrate higher levels of analytical and creative abilities in childhood, benefit from a supportive family background, invest in their human capital through diverse and longer work experience and have accrued a solid basic education, albeit not strongly credentialed.\n",
      "[The results, start-up, who, higher levels, analytical and creative abilities, childhood, a supportive family background, their human capital, diverse and longer work experience, a solid basic education]\n",
      "==================================================\n",
      "This article contributes to a better understanding of human capital acquisition during the unfolding entrepreneurial life-course.\n",
      "[This article, a better understanding, human capital acquisition, the unfolding entrepreneurial life-course]\n",
      "==================================================\n",
      "Mediators and moderators of the relationship between education, human capital and entrepreneurship are also identified by accentuating the importance of family processes.\n",
      "[Mediators, moderators, the relationship, education, human capital, entrepreneurship, the importance, family processes]\n",
      "==================================================\n",
      "In doing so, this study bridges the human capital and cultural capital literatures that have tended to evolve on separate tracks.\n",
      "[this study, the human capital and cultural capital literatures, separate tracks]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for sent in doc1.sents:\n",
    "    print(sent)\n",
    "    print(list(sent.noun_chunks))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical evidence for links between human capital and entrepreneurship potential is equivocal despite a wide range of studies.\n"
     ]
    }
   ],
   "source": [
    "sent1 = list(doc1.sents)[0]\n",
    "print(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Empirical evidence, links, human capital, entrepreneurship, potential, a wide range, studies]\n"
     ]
    }
   ],
   "source": [
    "print(list(doc.noun_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'sent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-8f893e4d9f68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mancestors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'sent'"
     ]
    }
   ],
   "source": [
    "for a in doc1.sent.noun_chunks:\n",
    "    print(a, a.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list(sent1.noun_chunks):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical ADJ\n",
      "evidence NOUN\n",
      "for ADP\n",
      "links NOUN\n",
      "between ADP\n",
      "human ADJ\n",
      "capital NOUN\n",
      "and CCONJ\n",
      "entrepreneurship NOUN\n",
      "potential NOUN\n",
      "is VERB\n",
      "equivocal ADJ\n",
      "despite ADP\n",
      "a DET\n",
      "wide ADJ\n",
      "range NOUN\n",
      "of ADP\n",
      "studies NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for s in sent1:\n",
    "    print(s, s.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = nlp(\"Empirical evidence for links between human capital and entrepreneurship potential is equivocal despite a wide range of studies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.token.Token' object has no attribute 'text_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-450a09e566bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%10s %5s %10s %10s %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdep_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'text_'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
